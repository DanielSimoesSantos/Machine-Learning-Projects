{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install updated versions of required packages\n",
        "!pip install -U ydata-profiling\n",
        "!pip install -U category_encoders\n",
        "!pip install -U numba==0.58.1\n",
        "\n",
        "# Importing python packages\n",
        "import os\n",
        "from os.path import join\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import plotly.express as px\n",
        "import scipy.stats as stats\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "\n",
        "# Importing the required packages\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.preprocessing import KBinsDiscretizer, MinMaxScaler, StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, recall_score,\n",
        "                             r2_score, mean_absolute_error, mean_squared_error, f1_score,\n",
        "                             classification_report, roc_auc_score, roc_curve)\n",
        "from sklearn.feature_selection import RFE, f_classif, SelectKBest\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.stats import chi2_contingency, spearmanr, pointbiserialr, randint\n",
        "from ydata_profiling import ProfileReport\n",
        "from datetime import datetime\n",
        "from math import ceil\n",
        "from itertools import combinations\n",
        "\n",
        "# Verify installations\n",
        "!pip list | grep -E \"ydata-profiling|category_encoders|numba\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flLWLP4KqoaP",
        "outputId": "88c8f963-42a4-4faa-c1e5-99b51ebad13a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ydata-profiling in /usr/local/lib/python3.10/dist-packages (4.10.0)\n",
            "Requirement already satisfied: scipy<1.14,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.9.3)\n",
            "Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.4.4)\n",
            "Requirement already satisfied: matplotlib<3.10,>=3.5 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (3.5.3)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (2.9.2)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (6.0.2)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (3.1.4)\n",
            "Requirement already satisfied: visions<0.7.7,>=0.7.5 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (0.7.5)\n",
            "Requirement already satisfied: numpy<2.2,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.23.5)\n",
            "Requirement already satisfied: htmlmin==0.1.12 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.1.12)\n",
            "Requirement already satisfied: phik<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (2.28.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (4.64.1)\n",
            "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.11.2)\n",
            "Requirement already satisfied: multimethod<2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.8)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.13.5)\n",
            "Requirement already satisfied: typeguard<5,>=3 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (4.3.0)\n",
            "Requirement already satisfied: imagehash==4.3.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (4.3.1)\n",
            "Requirement already satisfied: wordcloud>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.9.3)\n",
            "Requirement already satisfied: dacite>=1.8 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.8.1)\n",
            "Requirement already satisfied: numba<1,>=0.56.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.60.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling) (1.7.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (2.1.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.10,>=3.5->ydata-profiling) (2.9.0.post0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba<1,>=0.56.0->ydata-profiling) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2024.2)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2->ydata-profiling) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (2024.8.30)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (0.5.6)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (24.2.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (3.3)\n",
            "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling) (1.16.0)\n",
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.10/dist-packages (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.9.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.13.5)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.4.4)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.1)\n",
            "Collecting numba==0.58.1\n",
            "  Using cached numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba==0.58.1)\n",
            "  Using cached llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.10/dist-packages (from numba==0.58.1) (1.23.5)\n",
            "Using cached numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "Using cached llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
            "Installing collected packages: llvmlite, numba\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.4.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed llvmlite-0.41.1 numba-0.58.1\n",
            "numba                            0.58.1\n",
            "ydata-profiling                  4.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GxI1gy16rAay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0d1f84-bd87-42a8-8af9-a06ca2bc1b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# For GoogleColab versions\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "path = '/content/drive/MyDrive/Machine Learning Projects/Predictive Model'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p6QPk3QFsP0e"
      },
      "outputs": [],
      "source": [
        "# Save the train and test csv in dataframes accordingly\n",
        "traindf = pd.read_csv(path + '/train.csv')\n",
        "testdf = pd.read_csv(path + '/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPlZR3K1MWNN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3WMv6Jttc2q"
      },
      "source": [
        "# **1. Business Understanding**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuCS0ouiumyh"
      },
      "source": [
        "## MetaData\n",
        "\n",
        "* citizen_id: Unique identifier of the citizen.\n",
        "* Name: First name of each citizen.\n",
        "* Title: Title of each citizen.\n",
        "* date_of_birth: Date of birth of each citizen.\n",
        "* city: Name of citizen´s city.\n",
        "* country: Name of citizen´s country.\n",
        "* last_year_avg_monthly_charity_donations: The average of monthly charitable donations made by each citizen in the last year.\n",
        "* environmental_awareness_rating: A rating [0, 10] of each individual's awareness of and engagement with environmental issues.\n",
        "* financial_wellness_index: An index indicating each citizen´s overall financial health.\n",
        "* investment_portfolio_value: The value, in thousands of units of currency, of each citizen´s investment portfolio.\n",
        "* investments_risk_appetite: A measure of each individual's willingness to take risks in their investments.\n",
        "* investments_risk_tolerance: A measure of each individual's tolerance for risk in their investment choices.\n",
        "* tech_savviness_score: A score representing each citizen´s proficiency and comfort with technology.\n",
        "* social_media_influence_score: A score representing each citizen´s influence and activity on social media platforms.\n",
        "* entertainment_engagement_factor: A score representing each citizen´s engagement with entertainment activities.\n",
        "* avg_monthly_entertainment_expenses: The monthly expenditure on entertainment for each citizen, in units of currency.\n",
        "* avg_weekly_exercise_hours: The average number of hours each citizen spends on exercise weekly.\n",
        "* health_consciousness_rating: A rating [0, 10] of each citizen´s awareness and proactive behavior towards their health.\n",
        "* stress_management_score: A score indicating how effectively each citizen manages stress.\n",
        "* overall_well_being: A score indicating each citizen's overall status.\n",
        "* lifestyle_type: A categorization of the predominant lifestyle choice for each citizen (Target Variable).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyteJL3-0BKz"
      },
      "outputs": [],
      "source": [
        "# Count the number of observations for each \"category\" (1 and 0)\n",
        "traindf['lifestyle_type'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLI4kYIU0Iz8"
      },
      "source": [
        "**PREDICTIVE GOAL:**\n",
        "-explicar1\n",
        "-explicar2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF7NcuMq0HQb"
      },
      "source": [
        "# **2. Data Understanding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3kohoGx0ak5"
      },
      "outputs": [],
      "source": [
        "# Copy the original dfs to df_original so we can use it at any time in the script\n",
        "\n",
        "traindf_original = traindf\n",
        "testdf_original = testdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQQIlyxj0dqb"
      },
      "outputs": [],
      "source": [
        "# shape verification of the train dataframe, to see the number of rows and columns\n",
        "traindf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS6vXlv1znaf"
      },
      "outputs": [],
      "source": [
        "# Look at the dataset types\n",
        "traindf.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrOmaNejzC-U"
      },
      "outputs": [],
      "source": [
        "# Look at the header columns of the initial dataframe, and the first 5 rows\n",
        "traindf.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g71jzrjI0iRu"
      },
      "outputs": [],
      "source": [
        "# Check for duplicate recordID in the dataframe so we can pass it to an index\n",
        "traindf['citizen_id'].duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxHKrOr30xUt"
      },
      "outputs": [],
      "source": [
        "# record id as an index\n",
        "traindf.set_index('citizen_id', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2taNE1G3pHS7"
      },
      "outputs": [],
      "source": [
        "# The same trasformation is done to the test dataframe\n",
        "testdf.set_index('citizen_id', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypbeWOBQ1JXf"
      },
      "source": [
        "## Splitting the Dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH-KcxC41Lt6"
      },
      "source": [
        "Since we already have access to the Test dataframe, we will divide the traindf into distinct train and validation sets in order to check the models' accuracy. After that, we'll use the test set to generate predictions and determine results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qVYpLxa1xBD"
      },
      "source": [
        "From this point on, every transformation will be applied to the train set, validation set, and test set. Only those transformations that presuppose the removal of particular rows are not applied to the test set; as a result, those transformations are not taken into consideration for the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTSuMyfC2oMS"
      },
      "source": [
        "Considering points for Spliting:\n",
        "\n",
        "* validation_size = 0.3\n",
        "\n",
        "* random_state = 10\n",
        "* shuffle = True\n",
        "* stratify = y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IBgi4U220Bd"
      },
      "outputs": [],
      "source": [
        "# To make the separation of the train dataframe using train_test_split, we separate the target variable from the others and created X and Y to pass in the function.\n",
        "X = traindf.drop(columns=['lifestyle_type'])\n",
        "y = traindf['lifestyle_type']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMHNOwU65Idg"
      },
      "source": [
        "We want to separate in Train, Test and Validation sets.\n",
        "\n",
        "For that, we will first divide between train_validation and test. And then the train_validation in between train and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzaGsa0F5KAe"
      },
      "outputs": [],
      "source": [
        "# The following package was the one used to split the data. Uncomment to use it if required.\n",
        "# from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhrDNC9A5OLx"
      },
      "outputs": [],
      "source": [
        "# the final variables and the function to split the information accordingly to what was described before.\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, stratify = y, random_state=10, shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNoay-il6i2B"
      },
      "source": [
        "Now we have three different datasets:\n",
        "\n",
        "\n",
        "\n",
        "*  Trainining dataset: X_train & y_train - corresponding to 70% - serve to train the model and build it\n",
        "*  Validation set: X_val & y_val - corresponding to 30% - to validate the model and make some checks\n",
        "*  Test set: corresponding to the dataset that will be used to make the predictions - to evaluate the performance on the kagle competition\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7viVIrB6jm4"
      },
      "outputs": [],
      "source": [
        "# Looking to the train dataframe to check the initial structure of X_Train and make a first assessment\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bnlH3MT6vG4"
      },
      "outputs": [],
      "source": [
        "# Looking to the train dataframe to check the initial structure of y_Train and make a first assessment\n",
        "y_train.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxSrB3O_KQdN"
      },
      "outputs": [],
      "source": [
        "# We concat the X and y dataframes so all the addressed transformation from now on, can be excluded in the overall features and in the target features too with the same indexer.\n",
        "# To not replicate all the time the transformation and to decrease risks, we concat it now\n",
        "traindf = pd.concat([X_train, y_train], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nWT6a0YKV9l"
      },
      "outputs": [],
      "source": [
        "# We do the same for the validation set\n",
        "valdf = pd.concat([X_val, y_val], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to_mvjv8jrws"
      },
      "source": [
        "Since it's unclear whether the rating variables should be rounded, we will include both the original and rounded versions of these variables in each dataset. This will allow us to decide later whether or not to use them in the correlation matrix. Consequently, we will have two additional variables in the dataset\n",
        "- environmental_awareness_rating_rounded\n",
        "-health_consciousness_rating_rounded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL-6-obsj3w0"
      },
      "outputs": [],
      "source": [
        "# Round variables in traindf\n",
        "traindf['environmental_awareness_rating_rounded'] = traindf['environmental_awareness_rating'].round()\n",
        "traindf['health_consciousness_rating_rounded'] = traindf['health_consciousness_rating'].round()\n",
        "\n",
        "# Round variables in valdf\n",
        "valdf['environmental_awareness_rating_rounded'] = valdf['environmental_awareness_rating'].round()\n",
        "valdf['health_consciousness_rating_rounded'] = valdf['health_consciousness_rating'].round()\n",
        "\n",
        "# Round variables in testdf\n",
        "testdf['environmental_awareness_rating_rounded'] = testdf['environmental_awareness_rating'].round()\n",
        "testdf['health_consciousness_rating_rounded'] = testdf['health_consciousness_rating'].round()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpZCqbCftbER"
      },
      "source": [
        "As we think it will be helpfull to have a boolean with the gender, we also think will be helpfull to a age column.\n",
        "So, we have 2 new variables:\n",
        "- Gender\n",
        "- Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmKkySYWt3cB"
      },
      "outputs": [],
      "source": [
        "# Creating the gender column\n",
        "\n",
        "# Define the title to gender mapping\n",
        "title_to_gender = {\n",
        "    'Miss': 'Female',\n",
        "    'Mrs.': 'Female',\n",
        "    'Mr.': 'Male',\n",
        "    'Ms.': 'Female'\n",
        "}\n",
        "\n",
        "# Add a new column for gender based on the title in the training DataFrame\n",
        "traindf['gender'] = traindf['title'].map(title_to_gender)\n",
        "\n",
        "# Add a new column for gender based on the title in the validation DataFrame\n",
        "valdf['gender'] = valdf['title'].map(title_to_gender)\n",
        "\n",
        "# Add a new column for gender based on the title in the test DataFrame\n",
        "testdf['gender'] = testdf['title'].map(title_to_gender)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_yXSYeMwORC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the reference date\n",
        "reference_date = datetime(2024, 1, 1)\n",
        "\n",
        "# Function to calculate age\n",
        "def calculate_age(date_of_birth):\n",
        "    return (reference_date - pd.to_datetime(date_of_birth)).days // 365\n",
        "\n",
        "# Add the age column to the training DataFrame\n",
        "traindf['age'] = traindf['date_of_birth'].apply(calculate_age)\n",
        "\n",
        "# Add the age column to the validation DataFrame\n",
        "valdf['age'] = valdf['date_of_birth'].apply(calculate_age)\n",
        "\n",
        "# Add the age column to the test DataFrame\n",
        "testdf['age'] = testdf['date_of_birth'].apply(calculate_age)\n",
        "\n",
        "# Function to categorize age into intervals\n",
        "def age_interval(age):\n",
        "    if age < 10:\n",
        "        return '0-10'\n",
        "    elif age < 20:\n",
        "        return '10-20'\n",
        "    elif age < 30:\n",
        "        return '20-30'\n",
        "    elif age < 40:\n",
        "        return '30-40'\n",
        "    elif age < 50:\n",
        "        return '40-50'\n",
        "    elif age < 60:\n",
        "        return '50-60'\n",
        "    elif age < 70:\n",
        "        return '60-70'\n",
        "    else:\n",
        "        return '70+'\n",
        "\n",
        "# Add the Interval of ages column to the training DataFrame\n",
        "traindf['Interval of ages'] = traindf['age'].apply(age_interval)\n",
        "\n",
        "# Add the Interval of ages column to the validation DataFrame\n",
        "valdf['Interval of ages'] = valdf['age'].apply(age_interval)\n",
        "\n",
        "# Add the Interval of ages column to the test DataFrame\n",
        "testdf['Interval of ages'] = testdf['age'].apply(age_interval)\n",
        "\n",
        "# Print the first few rows of each DataFrame to verify\n",
        "print(traindf.head())\n",
        "print(valdf.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqhEwx7SKiAg"
      },
      "outputs": [],
      "source": [
        "# info on the train dataset\n",
        "traindf.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0AFzCgTLf0i"
      },
      "outputs": [],
      "source": [
        "# printing the na values for the different columns in the train dataset\n",
        "print(traindf.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-3CxqKvLigS"
      },
      "outputs": [],
      "source": [
        "# printing the na values for the different columns in the validation dataset\n",
        "print(valdf.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUcFMZ7-LxQO"
      },
      "outputs": [],
      "source": [
        "# Describing All Data\n",
        "# we do not make the same approach for the validation set because the base dataframe will be this one.\n",
        "traindf.describe(include = 'all').T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LyY3qasMSGQ"
      },
      "outputs": [],
      "source": [
        "# Describing Numerical Data\n",
        "traindf.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pip783IMaZw"
      },
      "outputs": [],
      "source": [
        "# Describing Categorical Data\n",
        "traindf.describe(include = ['O']).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie0dRiMWMrCb"
      },
      "source": [
        "# 2.1 Variables Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpklMhciMtU7"
      },
      "outputs": [],
      "source": [
        "# All the columns in the train dataframe\n",
        "traindf.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBeFu8kDNeSm"
      },
      "outputs": [],
      "source": [
        "# Defining the variables according to the datatypes so the transformations can be easy to implement, the visualizations to see and consistencies to verify\n",
        "\n",
        "metric_features = ['last_year_avg_monthly_charity_donations','environmental_awareness_rating','financial_wellness_index','investment_portfolio_value','investments_risk_appetite','investments_risk_tolerance','tech_savviness_score','social_media_influence_score','entertainment_engagement_factor','avg_monthly_entertainment_expenses','avg_weekly_exercise_hours','health_consciousness_rating','stress_management_score','overall_well_being','environmental_awareness_rating_rounded','health_consciousness_rating_rounded','age']\n",
        "categorical_features = ['name','title','date_of_birth','city','country','Interval of ages','gender']\n",
        "categorical_features_enc = ['city','country','Interval of ages','gender']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GCShkzVQ0-S"
      },
      "outputs": [],
      "source": [
        "# showing metric features only\n",
        "traindf[metric_features].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UhTkiUcQ5Uo"
      },
      "outputs": [],
      "source": [
        "# showing categorical features only\n",
        "traindf[categorical_features].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87Q8-GsKQ_zX"
      },
      "outputs": [],
      "source": [
        "# To verify if there any \"empty\" values\n",
        "print((traindf == '').sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cuLFm8FRI4N"
      },
      "outputs": [],
      "source": [
        "# To verify if there any \"empty\" values, but now on the validation set\n",
        "print((valdf == '').sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2V0ToS3RKah"
      },
      "outputs": [],
      "source": [
        "# To verify if there any \"empty\" values, but now on the test set\n",
        "print((testdf == '').sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GMICtsOWF5T"
      },
      "source": [
        "# 2.2 Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtDTwkPzt5ov"
      },
      "outputs": [],
      "source": [
        "traindf.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAfxT1N_uaOf"
      },
      "outputs": [],
      "source": [
        "valdf.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIsdyvwsugKO"
      },
      "outputs": [],
      "source": [
        "testdf.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE2BV0uOupRo"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes = traindf.copy()\n",
        "valdf_dtypes = valdf.copy()\n",
        "testdf_dtypes = testdf.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDM4sb1dsslF"
      },
      "source": [
        "# 2.3 Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2A2ykt6svP_"
      },
      "outputs": [],
      "source": [
        "# We create a profilingReport so we can address easily some points on the features and to get more and better insights on the data existent.\n",
        "# however, the profile is runned everytime.\n",
        "\n",
        "# Profiling for further detail analysis if required\n",
        "profile = ProfileReport(\n",
        "    traindf_dtypes,\n",
        "    title='WWW Profile',\n",
        "    correlations={\n",
        "        \"pearson\": {\"calculate\": True},\n",
        "        \"spearman\": {\"calculate\": False},\n",
        "        \"kendall\": {\"calculate\": False},\n",
        "        \"phi_k\": {\"calculate\": False},\n",
        "        \"cramers\": {\"calculate\": False},\n",
        "    },\n",
        ")\n",
        "\n",
        "# profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlGTiIv9wBgA"
      },
      "source": [
        "## Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHK-4BbDiYX1"
      },
      "outputs": [],
      "source": [
        "def plot_multiple_histograms(data, feats, title=\"Metrical' Histograms\", fig_size=(6,3)):\n",
        "\n",
        "    # Prepare figure. Create individual axes where each histogram will be placed\n",
        "    fig, axes = plt.subplots(2, ceil(len(feats) / 2), figsize=(30, 10))\n",
        "\n",
        "    # Plot data\n",
        "    # Iterate across axes objects and associate each histogram (hint: use the ax.hist() instead of plt.hist()):\n",
        "    for ax, feat in zip(axes.flatten(), feats): # Notice the zip() function and flatten() method\n",
        "      ax.hist(data[feat], bins=20)\n",
        "      ax.set_title(feat)\n",
        "      ax.tick_params(axis='both', which='major', labelsize=8)\n",
        "\n",
        "    # Layout\n",
        "    # Add a centered title to the figure:\n",
        "    plt.suptitle(title)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def plot_categorical_histograms(data, feats, title=\"Categorical Histograms\", fig_size=(6,3)):\n",
        "\n",
        "    # Prepare figure. Create individual axes where each histogram will be placed\n",
        "    fig, axes = plt.subplots(2, ceil(len(feats) / 2), figsize=(30, 10))\n",
        "\n",
        "    # Plot data\n",
        "    # Iterate across axes objects and associate each histogram (hint: use the ax.hist() instead of plt.hist()):\n",
        "    for ax, feat in zip(axes.flatten(), feats): # Notice the zip() function and flatten() method\n",
        "        sns.countplot(data=data, x=feat, ax=ax)\n",
        "        ax.set_title(feat)\n",
        "        ax.tick_params(axis='both', which='major', labelsize=8)\n",
        "\n",
        "    # Layout\n",
        "    # Add a centered title to the figure:\n",
        "    plt.suptitle(title)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def plot_boolean_histograms(data, feats, title=\"Boolean Histograms\", fig_size=(6,3)):\n",
        "\n",
        "    # Prepare figure. Create individual axes where each histogram will be placed\n",
        "    fig, axes = plt.subplots(2, ceil(len(feats) / 2), figsize=(30, 10))\n",
        "\n",
        "    # Plot data\n",
        "    # Iterate across axes objects and associate each histogram (hint: use the ax.hist() instead of plt.hist()):\n",
        "    for ax, feat in zip(axes.flatten(), feats): # Notice the zip() function and flatten() method\n",
        "        sns.countplot(data=data, x=feat, ax=ax)\n",
        "        ax.set_title(feat)\n",
        "        ax.tick_params(axis='both', which='major', labelsize=8)\n",
        "        ax.set_xticklabels(['False', 'True'])\n",
        "\n",
        "    # Layout\n",
        "    # Add a centered title to the figure:\n",
        "    plt.suptitle(title)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "## Define a function that plots multiple box plots\n",
        "\n",
        "def plot_multiple_boxplots(data, feats, title=\"Metric Features Box Plots\"):\n",
        "\n",
        "    # Prepare figure. Create individual axes where each histogram will be placed\n",
        "    fig, axes = plt.subplots(2, ceil(len(feats) /2), figsize=(30, 10))\n",
        "\n",
        "    # Plot data\n",
        "    # Iterate across axes objects and associate each histogram (hint: use the ax.hist() instead of plt.hist()):\n",
        "    for ax, feat in zip(axes.flatten(), feats): # Notice the zip() function and flatten() method\n",
        "      sns.boxplot(x=data[feat], ax=ax)\n",
        "      ax.set_title(feat)\n",
        "\n",
        "    # Layout\n",
        "    # Add a centered title to the figure:\n",
        "    plt.suptitle(title)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJZCP2-v0L33"
      },
      "source": [
        "### Metric Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxomjcYdwAJG"
      },
      "outputs": [],
      "source": [
        "# Setting the seaborn package\n",
        "sns.set()\n",
        "\n",
        "# Plot the different metric features to visualize them and understand their distribution\n",
        "plot_multiple_histograms(traindf_dtypes, metric_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0zn8vH70Sx1"
      },
      "source": [
        "### Adressing the negative values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM4v7zNL1Dwq"
      },
      "source": [
        "**TRAIN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zHlX4To45tA"
      },
      "source": [
        "TREATING NEGATIVE VALUES - last_year_avg_monthly_charity_donations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIS7uKSU1FEd"
      },
      "outputs": [],
      "source": [
        "# Verifying the negative values first\n",
        "(traindf_dtypes['last_year_avg_monthly_charity_donations'] < 0).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7J40epjy4rKR"
      },
      "outputs": [],
      "source": [
        "# Drop rows with negative values in 'last_year_avg_monthly_charity_donations' column\n",
        "traindf_dtypes = traindf_dtypes[traindf_dtypes['last_year_avg_monthly_charity_donations'] >= 0]\n",
        "\n",
        "# Verify that negative values are removed\n",
        "print(traindf_dtypes[traindf_dtypes['last_year_avg_monthly_charity_donations'] < 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SwrNzGb5A6c"
      },
      "source": [
        "TREATING NEGATIVE VALUES - avg_weekly_exercise_hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "840UdtB849mP"
      },
      "outputs": [],
      "source": [
        "# Verifying the negative values first\n",
        "(traindf_dtypes['avg_weekly_exercise_hours'] < 0).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjknmDO952G7"
      },
      "outputs": [],
      "source": [
        "# Drop rows with negative values in 'last_year_avg_monthly_charity_donations' column\n",
        "traindf_dtypes = traindf_dtypes[traindf_dtypes['avg_weekly_exercise_hours'] >= 0]\n",
        "\n",
        "# Verify that negative values are removed\n",
        "print(traindf_dtypes[traindf_dtypes['avg_weekly_exercise_hours'] < 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1baB1G6S6A6F"
      },
      "source": [
        "**VALIDATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIvdpMmK6EbW"
      },
      "source": [
        "\n",
        "TREATING NEGATIVE VALUES - last_year_avg_monthly_charity_donations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0iKNIeY6Esn"
      },
      "outputs": [],
      "source": [
        "# Verifying the negative values first\n",
        "(valdf_dtypes['last_year_avg_monthly_charity_donations'] < 0).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McPovAk66OsP"
      },
      "outputs": [],
      "source": [
        "# Drop rows with negative values in 'last_year_avg_monthly_charity_donations' column\n",
        "valdf_dtypes = valdf_dtypes[valdf_dtypes['last_year_avg_monthly_charity_donations'] >= 0]\n",
        "\n",
        "# Verify that negative values are removed\n",
        "print(valdf_dtypes[valdf_dtypes['last_year_avg_monthly_charity_donations'] < 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak6nZnUv6FIy"
      },
      "source": [
        "TREATING NEGATIVE VALUES - avg_weekly_exercise_hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nalnOdb6ZAz"
      },
      "outputs": [],
      "source": [
        "# Verifying the negative values first\n",
        "(valdf_dtypes['avg_weekly_exercise_hours'] < 0).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnxbjJPd6Y2A"
      },
      "outputs": [],
      "source": [
        "# Drop rows with negative values in 'last_year_avg_monthly_charity_donations' column\n",
        "valdf_dtypes = valdf_dtypes[valdf_dtypes['avg_weekly_exercise_hours'] >= 0]\n",
        "\n",
        "# Verify that negative values are removed\n",
        "print(valdf_dtypes[valdf_dtypes['avg_weekly_exercise_hours'] < 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnaqcan0zrSG"
      },
      "source": [
        "**TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFV8dfdv0Y-v"
      },
      "outputs": [],
      "source": [
        "#(testdf_dtypes['last_year_avg_monthly_charity_donations'] < 0).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgJqQ9ie0ZjB"
      },
      "outputs": [],
      "source": [
        "#testdf_dtypes = testdf_dtypes[testdf_dtypes['last_year_avg_monthly_charity_donations'] >= 0]\n",
        "\n",
        "# Verify that negative values are removed\n",
        "#print(testdf_dtypes[testdf_dtypes['last_year_avg_monthly_charity_donations'] < 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I06kGebUDttI"
      },
      "outputs": [],
      "source": [
        "#(testdf_dtypes['avg_weekly_exercise_hours'] < 0).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWNUFV2TzoCY"
      },
      "outputs": [],
      "source": [
        "testdf_dtypes = testdf\n",
        "#testdf_dtypes = testdf_dtypes[testdf_dtypes['avg_weekly_exercise_hours'] >= 0]\n",
        "\n",
        "# Verify that negative values are removed\n",
        "#print(testdf_dtypes[testdf_dtypes['avg_weekly_exercise_hours'] < 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3ioePwLxhd_"
      },
      "source": [
        "## Boxplots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI16nLg00koW"
      },
      "source": [
        "### Delaying the Outliers removal\n",
        "\n",
        "As we see, we have a lot of outliers. Since we have this many outliers, we will first analyze the correlation and pairwise matrix's."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvvpk6hBxmqB"
      },
      "outputs": [],
      "source": [
        "# Multiple boxplots plotted for the metric features\n",
        "plot_multiple_boxplots(traindf_dtypes, metric_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbQqzxub0imW"
      },
      "source": [
        "## Pairwise Relationships"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M6fX_4Fc023s"
      },
      "outputs": [],
      "source": [
        "#Pairwise Relationship of All Numerical Variables\n",
        "sns.set()\n",
        "\n",
        "#Setting pairplot\n",
        "sns.pairplot(traindf_dtypes[metric_features], diag_kind=\"hist\")\n",
        "\n",
        "#Layout\n",
        "plt.subplots_adjust(top=0.95)\n",
        "plt.suptitle(\"Pairwise Relationship of Variables\", fontsize=20)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83IwtXN8mdCj"
      },
      "source": [
        "## Correlation Matrix - Before Outliers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpxHf6-y3S9O"
      },
      "source": [
        "### Metric Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9RHSsTr0naQg"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_corr = traindf_dtypes.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bAO01_Fwnf-z"
      },
      "outputs": [],
      "source": [
        "valdf_dtypes_corr = valdf_dtypes.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vI9azoLPngzo"
      },
      "outputs": [],
      "source": [
        "testdf_dtypes_corr = testdf_dtypes.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t9ahHIlxM86M"
      },
      "outputs": [],
      "source": [
        "# Prepare figure\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Obtain correlation matrix. Round the values to 1 decimal cases. Use the DataFrame corr() and round() method.\n",
        "corr = np.round(traindf_dtypes_corr[metric_features].corr(method=\"pearson\"), decimals=1)\n",
        "\n",
        "# Build annotation matrix (values above |0.7| will appear annotated in the plot)\n",
        "mask_annot = np.absolute(corr.values) >= 0.7\n",
        "annot = np.where(mask_annot, corr.values, np.full(corr.shape,\"\")) # Try to understand what this np.where() does\n",
        "\n",
        "\n",
        "\n",
        "# Plot heatmap of the correlation matrix\n",
        "sns.heatmap(data=corr, annot=annot, cmap=sns.diverging_palette(240, 240, as_cmap=True),\n",
        "            fmt='s', vmin=-1, vmax=1, center=0, square=True, linewidths=.5)\n",
        "\n",
        "# Layout\n",
        "fig.subplots_adjust(top=0.95)\n",
        "fig.suptitle(\"Correlation Matrix\", fontsize=20)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlPKG74BtDXq"
      },
      "source": [
        "After analysing the correlation matrix, we know that we migh be droping both \"stress_management_score\" and \"overall_well_being\", therefore we will not treat the outliers of these variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ji0tsUxA58yX"
      },
      "outputs": [],
      "source": [
        "# Sum the absolute correlations for each variable\n",
        "sum_of_correlations = corr.abs().sum(axis=1)\n",
        "\n",
        "# Sort the sum of correlations in ascending order\n",
        "sorted_sum_of_correlations = sum_of_correlations.sort_values()\n",
        "\n",
        "# Print the sum of correlations for each variable in ascending order\n",
        "print(sorted_sum_of_correlations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJGPpQCjxnVl"
      },
      "source": [
        "BOX PLOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JX9PrIkg388m"
      },
      "outputs": [],
      "source": [
        "# Multiple boxplots plotted for the metric features\n",
        "plot_multiple_boxplots(traindf_dtypes, metric_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhiesKspzWOD"
      },
      "source": [
        "#### Outlier Removal - Manual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z-toOylVBmIq"
      },
      "outputs": [],
      "source": [
        "#investments_risk_appetite                  1.4\n",
        "#tech_savviness_score                       1.6\n",
        "#investment_portfolio_value                 2.0\n",
        "#avg_monthly_entertainment_expenses         2.9\n",
        "#health_consciousness_rating                3.3\n",
        "#environmental_awareness_rating             3.3\n",
        "\n",
        "filters1 = (\n",
        "    (traindf_dtypes['environmental_awareness_rating'] <10) &\n",
        "    (traindf_dtypes['investment_portfolio_value'] <= 400) &\n",
        "    (traindf_dtypes['investments_risk_tolerance'] <= 40) &\n",
        "    (traindf_dtypes['tech_savviness_score'] <= 30) &\n",
        "    (traindf_dtypes['social_media_influence_score'] <= 40) &\n",
        "    (traindf_dtypes['entertainment_engagement_factor'] <= 4) &\n",
        "    (traindf_dtypes['avg_monthly_entertainment_expenses'] <= 165) &\n",
        "    (traindf_dtypes['avg_weekly_exercise_hours'] < 8) &\n",
        "    (traindf_dtypes['health_consciousness_rating'] <= 11) &\n",
        "    (traindf_dtypes['stress_management_score'] <= 9) &\n",
        "    (traindf_dtypes['overall_well_being'] <= 450))\n",
        "\n",
        "\n",
        "traindf_dtypes_outlierm = traindf_dtypes[filters1]\n",
        "\n",
        "print('Percentage of data kept after removing outliers:', np.round(traindf_dtypes_outlierm.shape[0] / traindf_dtypes.shape[0], 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "djo4o-tgJsu0"
      },
      "outputs": [],
      "source": [
        "# Losing almost 22% of the dataset is too much, and still not solving the real problem. We continue with the outliers as we can see below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1ZL2keuFpJY6"
      },
      "outputs": [],
      "source": [
        "plot_multiple_boxplots(traindf_dtypes_outlierm, metric_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODmNWOxrKaP3"
      },
      "source": [
        "#### Outlier Removal - IQR Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nY9DwN2hKa4J"
      },
      "outputs": [],
      "source": [
        "# Loop through each column in the dataframe\n",
        "\n",
        "for column in traindf_dtypes[metric_features].columns:\n",
        "  # Calculate Q1, Q3, and IQR for the column\n",
        "  Q1 = traindf_dtypes[metric_features][column].quantile(0.25)\n",
        "  Q3 = traindf_dtypes[metric_features][column].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "\n",
        "  # Determine the lower and upper bounds for the column\n",
        "  lower_bound = Q1 - 1.5 * IQR\n",
        "  upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "  # Remove rows with values that fall outside the bounds\n",
        "  traindf_dtypes_mf_outlieriqr = traindf_dtypes[metric_features][(traindf_dtypes[metric_features][column] >= lower_bound) & (traindf_dtypes[metric_features][column] <= upper_bound)]\n",
        "\n",
        "# The dataframe now contains only rows with values within the bounds for all columns\n",
        "\n",
        "print('Percentage of data kept after removing outliers:', np.round(traindf_dtypes_mf_outlieriqr.shape[0] / traindf_dtypes.shape[0], 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vhnUmccHKhXT"
      },
      "outputs": [],
      "source": [
        "plot_multiple_boxplots(traindf_dtypes_mf_outlieriqr, metric_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3oLTTGgLSvc"
      },
      "source": [
        "We retain most of the data with this strategy, but there are still some outliers that may not be important for understanding the model's forecast. We'll take a different tack and use limit imposition to investigate the findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEy_SSMNLVP8"
      },
      "source": [
        "#### Outlier Limit Inputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tYRRyN2DLg6l"
      },
      "outputs": [],
      "source": [
        "# showing the initial without transformations again\n",
        "plot_multiple_boxplots(traindf_dtypes, metric_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hKMUlMLPMm_O"
      },
      "outputs": [],
      "source": [
        "# Copying the before dataframe for the new where the outliers will be treated\n",
        "traindf_dtypes_outlier = traindf_dtypes.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fGi93Mc7MsVl"
      },
      "outputs": [],
      "source": [
        "# All the values for seen as outliers in the boxplots will be stacked to the new maximum limit defined below.\n",
        "environmental_awareness_rating = traindf_dtypes['environmental_awareness_rating'].copy()\n",
        "environmental_awareness_rating.loc[environmental_awareness_rating>9] =9\n",
        "print(environmental_awareness_rating[environmental_awareness_rating == 9].count())\n",
        "traindf_dtypes_outlier['environmental_awareness_rating'] = environmental_awareness_rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XbfCrPNPO-Ky"
      },
      "outputs": [],
      "source": [
        "financial_wellness_index = traindf_dtypes['financial_wellness_index'].copy()\n",
        "financial_wellness_index.loc[financial_wellness_index>400] = 400\n",
        "#financial_wellness_index.loc[financial_wellness_index<20] = 20\n",
        "print(financial_wellness_index[financial_wellness_index == 400].count())\n",
        "#print(financial_wellness_index[financial_wellness_index == 20].count())\n",
        "traindf_dtypes_outlier['financial_wellness_index'] = financial_wellness_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KQifOMYFQBq7"
      },
      "outputs": [],
      "source": [
        "investment_portfolio_value = traindf_dtypes['investment_portfolio_value'].copy()\n",
        "investment_portfolio_value.loc[investment_portfolio_value>300] =300\n",
        "print(investment_portfolio_value[investment_portfolio_value == 300].count())\n",
        "traindf_dtypes_outlier['investment_portfolio_value'] = investment_portfolio_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sxM2cRxlSFmI"
      },
      "outputs": [],
      "source": [
        "investments_risk_tolerance = traindf_dtypes['investments_risk_tolerance'].copy()\n",
        "investments_risk_tolerance.loc[investments_risk_tolerance>28] = 28\n",
        "print(investments_risk_tolerance[investments_risk_tolerance == 28].count())\n",
        "traindf_dtypes_outlier['investments_risk_tolerance'] = investments_risk_tolerance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5iCkivv6Sd3-"
      },
      "outputs": [],
      "source": [
        "tech_savviness_score = traindf_dtypes['tech_savviness_score'].copy()\n",
        "tech_savviness_score.loc[tech_savviness_score>20] =20\n",
        "tech_savviness_score.loc[tech_savviness_score<8] = 8\n",
        "print(tech_savviness_score[tech_savviness_score == 20].count())\n",
        "print(tech_savviness_score[tech_savviness_score == 8].count())\n",
        "traindf_dtypes_outlier['tech_savviness_score'] = tech_savviness_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3PNKXxaYSnbr"
      },
      "outputs": [],
      "source": [
        "social_media_influence_score = traindf_dtypes['social_media_influence_score'].copy()\n",
        "social_media_influence_score.loc[social_media_influence_score>27] =27\n",
        "print(social_media_influence_score[social_media_influence_score == 27].count())\n",
        "traindf_dtypes_outlier['social_media_influence_score'] = social_media_influence_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T4iHv7wgd4Hg"
      },
      "outputs": [],
      "source": [
        "avg_monthly_entertainment_expenses = traindf_dtypes['avg_monthly_entertainment_expenses'].copy()\n",
        "avg_monthly_entertainment_expenses.loc[avg_monthly_entertainment_expenses>150] = 150\n",
        "print(avg_monthly_entertainment_expenses[avg_monthly_entertainment_expenses == 150].count())\n",
        "traindf_dtypes_outlier['avg_monthly_entertainment_expenses'] = avg_monthly_entertainment_expenses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NaqpiICleQem"
      },
      "outputs": [],
      "source": [
        "avg_weekly_exercise_hours = traindf_dtypes['avg_weekly_exercise_hours'].copy()\n",
        "avg_weekly_exercise_hours.loc[avg_weekly_exercise_hours>7] = 7\n",
        "print(avg_weekly_exercise_hours[avg_weekly_exercise_hours == 7].count())\n",
        "traindf_dtypes_outlier['avg_weekly_exercise_hours'] = avg_weekly_exercise_hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0qvWD2WqedAL"
      },
      "outputs": [],
      "source": [
        "health_consciousness_rating = traindf_dtypes['health_consciousness_rating'].copy()\n",
        "health_consciousness_rating.loc[health_consciousness_rating>9] = 9\n",
        "print(health_consciousness_rating[health_consciousness_rating == 9].count())\n",
        "traindf_dtypes_outlier['health_consciousness_rating'] = health_consciousness_rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzUSWcNGhkcW"
      },
      "source": [
        "With this last method, we treat the outliers and do not lose any % of the data set\n",
        "\n",
        "we end up with the df: **traindf_dtypes_outlier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjxDwmduhr7N"
      },
      "source": [
        "The same is applied for the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YmLWMbkuh4hK"
      },
      "outputs": [],
      "source": [
        "valdf_dtypes_outlier = valdf_dtypes.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tPshtrQwhtrP"
      },
      "outputs": [],
      "source": [
        "# All the values for seen as outliers in the boxplots will be stacked to the new maximum limit defined below.\n",
        "environmental_awareness_rating = valdf_dtypes['environmental_awareness_rating'].copy()\n",
        "environmental_awareness_rating.loc[environmental_awareness_rating>9] =9\n",
        "print(environmental_awareness_rating[environmental_awareness_rating == 9].count())\n",
        "valdf_dtypes_outlier['environmental_awareness_rating'] = environmental_awareness_rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LQ5ozhnPiBL4"
      },
      "outputs": [],
      "source": [
        "financial_wellness_index = valdf_dtypes['financial_wellness_index'].copy()\n",
        "financial_wellness_index.loc[financial_wellness_index>400] = 400\n",
        "#financial_wellness_index.loc[financial_wellness_index<20] = 20\n",
        "print(financial_wellness_index[financial_wellness_index == 400].count())\n",
        "#print(financial_wellness_index[financial_wellness_index == 20].count())\n",
        "valdf_dtypes_outlier['financial_wellness_index'] = financial_wellness_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FXFkWPUfiKCb"
      },
      "outputs": [],
      "source": [
        "investment_portfolio_value = valdf_dtypes['investment_portfolio_value'].copy()\n",
        "investment_portfolio_value.loc[investment_portfolio_value>300] =300\n",
        "print(investment_portfolio_value[investment_portfolio_value == 300].count())\n",
        "valdf_dtypes_outlier['investment_portfolio_value'] = investment_portfolio_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4SaVee14iMdL"
      },
      "outputs": [],
      "source": [
        "investments_risk_tolerance = valdf_dtypes['investments_risk_tolerance'].copy()\n",
        "investments_risk_tolerance.loc[investments_risk_tolerance>28] = 28\n",
        "print(investments_risk_tolerance[investments_risk_tolerance == 28].count())\n",
        "valdf_dtypes_outlier['investments_risk_tolerance'] = investments_risk_tolerance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "epHPTn-QiUOQ"
      },
      "outputs": [],
      "source": [
        "tech_savviness_score = valdf_dtypes['tech_savviness_score'].copy()\n",
        "tech_savviness_score.loc[tech_savviness_score>20] =20\n",
        "tech_savviness_score.loc[tech_savviness_score<8] = 8\n",
        "print(tech_savviness_score[tech_savviness_score == 20].count())\n",
        "print(tech_savviness_score[tech_savviness_score == 8].count())\n",
        "valdf_dtypes_outlier['tech_savviness_score'] = tech_savviness_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yRO50L1PiYWl"
      },
      "outputs": [],
      "source": [
        "social_media_influence_score = valdf_dtypes['social_media_influence_score'].copy()\n",
        "social_media_influence_score.loc[social_media_influence_score>27] =27\n",
        "print(social_media_influence_score[social_media_influence_score == 27].count())\n",
        "valdf_dtypes_outlier['social_media_influence_score'] = social_media_influence_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "raJ19wP2iahv"
      },
      "outputs": [],
      "source": [
        "avg_monthly_entertainment_expenses = valdf_dtypes['avg_monthly_entertainment_expenses'].copy()\n",
        "avg_monthly_entertainment_expenses.loc[avg_monthly_entertainment_expenses>150] = 150\n",
        "print(avg_monthly_entertainment_expenses[avg_monthly_entertainment_expenses == 150].count())\n",
        "valdf_dtypes_outlier['avg_monthly_entertainment_expenses'] = avg_monthly_entertainment_expenses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WuE4-AOAi3L-"
      },
      "outputs": [],
      "source": [
        "avg_weekly_exercise_hours = valdf_dtypes['avg_weekly_exercise_hours'].copy()\n",
        "avg_weekly_exercise_hours.loc[avg_weekly_exercise_hours>7] = 7\n",
        "print(avg_weekly_exercise_hours[avg_weekly_exercise_hours == 7].count())\n",
        "valdf_dtypes_outlier['avg_weekly_exercise_hours'] = avg_weekly_exercise_hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YJgcHrLPi7Hs"
      },
      "outputs": [],
      "source": [
        "health_consciousness_rating = valdf_dtypes['health_consciousness_rating'].copy()\n",
        "health_consciousness_rating.loc[health_consciousness_rating>9] = 9\n",
        "print(health_consciousness_rating[health_consciousness_rating == 9].count())\n",
        "valdf_dtypes_outlier['health_consciousness_rating'] = health_consciousness_rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lba6S9iyjCzh"
      },
      "source": [
        "The same is applied for the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GK08P8UjjJLQ"
      },
      "outputs": [],
      "source": [
        "testdf_dtypes_outlier = testdf_dtypes.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3P_3cLQYjPlE"
      },
      "outputs": [],
      "source": [
        "# All the values for seen as outliers in the boxplots will be stacked to the new maximum limit defined below.\n",
        "environmental_awareness_rating = testdf_dtypes['environmental_awareness_rating'].copy()\n",
        "environmental_awareness_rating.loc[environmental_awareness_rating>9] =9\n",
        "print(environmental_awareness_rating[environmental_awareness_rating == 9].count())\n",
        "testdf_dtypes_outlier['environmental_awareness_rating'] = environmental_awareness_rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ycZGHabejS-U"
      },
      "outputs": [],
      "source": [
        "financial_wellness_index = testdf_dtypes['financial_wellness_index'].copy()\n",
        "financial_wellness_index.loc[financial_wellness_index>400] = 400\n",
        "#financial_wellness_index.loc[financial_wellness_index<20] = 20\n",
        "print(financial_wellness_index[financial_wellness_index == 400].count())\n",
        "#print(financial_wellness_index[financial_wellness_index == 20].count())\n",
        "testdf_dtypes_outlier['financial_wellness_index'] = financial_wellness_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j3PKNbD4jaq8"
      },
      "outputs": [],
      "source": [
        "investment_portfolio_value = testdf_dtypes['investment_portfolio_value'].copy()\n",
        "investment_portfolio_value.loc[investment_portfolio_value>300] =300\n",
        "print(investment_portfolio_value[investment_portfolio_value == 300].count())\n",
        "testdf_dtypes_outlier['investment_portfolio_value'] = investment_portfolio_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qj6_He0YjdM0"
      },
      "outputs": [],
      "source": [
        "investments_risk_tolerance = testdf_dtypes['investments_risk_tolerance'].copy()\n",
        "investments_risk_tolerance.loc[investments_risk_tolerance>28] = 28\n",
        "print(investments_risk_tolerance[investments_risk_tolerance == 28].count())\n",
        "testdf_dtypes_outlier['investments_risk_tolerance'] = investments_risk_tolerance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AaGByEddjowK"
      },
      "outputs": [],
      "source": [
        "tech_savviness_score = testdf_dtypes['tech_savviness_score'].copy()\n",
        "tech_savviness_score.loc[tech_savviness_score>20] =20\n",
        "tech_savviness_score.loc[tech_savviness_score<8] = 8\n",
        "print(tech_savviness_score[tech_savviness_score == 20].count())\n",
        "print(tech_savviness_score[tech_savviness_score == 8].count())\n",
        "testdf_dtypes_outlier['tech_savviness_score'] = tech_savviness_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J2CaqyjMjryJ"
      },
      "outputs": [],
      "source": [
        "social_media_influence_score = testdf_dtypes['social_media_influence_score'].copy()\n",
        "social_media_influence_score.loc[social_media_influence_score>27] =27\n",
        "print(social_media_influence_score[social_media_influence_score == 27].count())\n",
        "testdf_dtypes_outlier['social_media_influence_score'] = social_media_influence_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IRRmY1Igj5rt"
      },
      "outputs": [],
      "source": [
        "avg_monthly_entertainment_expenses = testdf_dtypes['avg_monthly_entertainment_expenses'].copy()\n",
        "avg_monthly_entertainment_expenses.loc[avg_monthly_entertainment_expenses>150] = 150\n",
        "print(avg_monthly_entertainment_expenses[avg_monthly_entertainment_expenses == 150].count())\n",
        "testdf_dtypes_outlier['avg_monthly_entertainment_expenses'] = avg_monthly_entertainment_expenses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Sb34XKvPj3-_"
      },
      "outputs": [],
      "source": [
        "avg_weekly_exercise_hours = testdf_dtypes['avg_weekly_exercise_hours'].copy()\n",
        "avg_weekly_exercise_hours.loc[avg_weekly_exercise_hours>7] = 7\n",
        "print(avg_weekly_exercise_hours[avg_weekly_exercise_hours == 7].count())\n",
        "testdf_dtypes_outlier['avg_weekly_exercise_hours'] = avg_weekly_exercise_hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3l4NIIjkkBN1"
      },
      "outputs": [],
      "source": [
        "health_consciousness_rating = testdf_dtypes['health_consciousness_rating'].copy()\n",
        "health_consciousness_rating.loc[health_consciousness_rating>9] = 9\n",
        "print(health_consciousness_rating[health_consciousness_rating == 9].count())\n",
        "testdf_dtypes_outlier['health_consciousness_rating'] = health_consciousness_rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jeVFeOugou1"
      },
      "source": [
        "## Correlation Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCiO15ldgHrT"
      },
      "source": [
        "### Metric Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nNhjdXQ-hFkj"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr = traindf_dtypes_outlier.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nmp5OQJfhVwU"
      },
      "outputs": [],
      "source": [
        "valdf_dtypes_outlier_corr = valdf_dtypes_outlier.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kevONuxghXNj"
      },
      "outputs": [],
      "source": [
        "testdf_dtypes_outlier_corr = testdf_dtypes_outlier.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCd10Bg2FG8O"
      },
      "source": [
        "#### Correlation between features\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a22sBv0WFFhD"
      },
      "outputs": [],
      "source": [
        "# Prepare figure\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Obtain correlation matrix. Round the values to 1 decimal cases. Use the DataFrame corr() and round() method.\n",
        "corr = np.round(traindf_dtypes_outlier_corr[metric_features].corr(method=\"pearson\"), decimals=1)\n",
        "\n",
        "# Build annotation matrix (values above |0.7| will appear annotated in the plot)\n",
        "mask_annot = np.absolute(corr.values) >= 0.7\n",
        "annot = np.where(mask_annot, corr.values, np.full(corr.shape,\"\")) # Try to understand what this np.where() does\n",
        "\n",
        "\n",
        "\n",
        "# Plot heatmap of the correlation matrix\n",
        "sns.heatmap(data=corr, annot=annot, cmap=sns.diverging_palette(240, 240, as_cmap=True),\n",
        "            fmt='s', vmin=-1, vmax=1, center=0, square=True, linewidths=.5)\n",
        "\n",
        "# Layout\n",
        "fig.subplots_adjust(top=0.95)\n",
        "fig.suptitle(\"Correlation Matrix\", fontsize=20)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHuMLJJMGdfV"
      },
      "source": [
        "Variable \"stress_management_score\" and \"overall_well_being\" are correlated with other variables, so we will drop it.\n",
        "We will also drop \"environmental_awareness_rating_rounded\" and \"health_consciousness_rating_rounded\" as it didn't proved it would improve our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbfBFT_AJiQL"
      },
      "outputs": [],
      "source": [
        "# List of columns to drop\n",
        "columns_to_drop = [\n",
        "    'stress_management_score',\n",
        "    'overall_well_being',\n",
        "    'environmental_awareness_rating_rounded',\n",
        "    'health_consciousness_rating_rounded'\n",
        "]\n",
        "\n",
        "# Dropping columns from train, val, and test sets\n",
        "traindf_dtypes_outlier_corr.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
        "valdf_dtypes_outlier_corr.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
        "testdf_dtypes_outlier_corr.drop(columns=columns_to_drop, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA6btOrlHKbn"
      },
      "outputs": [],
      "source": [
        "metric_features = [feature for feature in metric_features if feature not in columns_to_drop]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjKKTeXJK_oI"
      },
      "source": [
        "#### Dependency with lifestyle_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMESCLnULAw8"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import f_oneway\n",
        "import pandas as pd\n",
        "\n",
        "# Create a copy of the dataframe to avoid altering the original dataframe\n",
        "df_copy = traindf_dtypes_outlier_corr.copy()\n",
        "\n",
        "# Convert lifestyle_type to numerical codes in the copied dataframe\n",
        "df_copy['lifestyle_type_code'] = df_copy['lifestyle_type'].astype('category').cat.codes\n",
        "\n",
        "# Dictionary to hold feature and their ANOVA F-value and p-value with lifestyle_type\n",
        "anova_dict = {}\n",
        "\n",
        "# Perform one-way ANOVA for each metric feature\n",
        "for feature in metric_features:\n",
        "    # Create groups for each lifestyle_type_code\n",
        "    groups = []\n",
        "    for code in df_copy['lifestyle_type_code'].unique():\n",
        "        group = df_copy[df_copy['lifestyle_type_code'] == code][feature]\n",
        "        groups.append(group)\n",
        "\n",
        "    # Check if all groups have data\n",
        "    if all(len(group) > 0 for group in groups):\n",
        "        # Perform ANOVA\n",
        "        f_val, p_val = f_oneway(*groups)\n",
        "        anova_dict[feature] = {'F-value': f_val, 'p-value': p_val}\n",
        "    else:\n",
        "        warnings.warn(f'One of the groups for feature {feature} is empty. Skipping ANOVA for this feature.')\n",
        "\n",
        "# Set your p-value threshold\n",
        "p_value_threshold = 0.05  # Common choice for p-value threshold\n",
        "\n",
        "# Get features with p-value above threshold (less statistically significant features)\n",
        "insignificant_features = [feature for feature, result in anova_dict.items() if result['p-value'] > p_value_threshold]\n",
        "\n",
        "print(\"Features less likely to be significant with lifestyle_type:\")\n",
        "for feature in insignificant_features:\n",
        "    print(f'{feature}: F-value: {anova_dict[feature][\"F-value\"]:.3f}, p-value: {anova_dict[feature][\"p-value\"]:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6bDG5TTOupI"
      },
      "source": [
        "### Boolean Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iM9aKbrPGME"
      },
      "source": [
        "There are no booleans in our data set. Nothing needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7J7HCFBPN4q"
      },
      "source": [
        "### Categorical Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znNkk0mzPWB4"
      },
      "source": [
        "#### Dependency with lifestyle_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fTUkaLtPXTU"
      },
      "outputs": [],
      "source": [
        "# get categorical features\n",
        "cat_features = traindf_dtypes_outlier_corr[categorical_features]\n",
        "\n",
        "# iterate over each categorical feature and compute chi2 test\n",
        "for feature in categorical_features:\n",
        "    contingency_table = pd.crosstab(cat_features[feature], traindf_dtypes_outlier_corr['lifestyle_type'])\n",
        "    _, p, _, _ = chi2_contingency(contingency_table)\n",
        "    print(f\"{feature}: P-value={p}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0P4WjrbP22U"
      },
      "source": [
        "Features like name, title, date_of_birth, city, and country don't seem to have any significant association with lifestyle type.\n",
        "The test confirms what's already known: there's a significant association between the lifestyle_type and itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwcbZp11P5bO"
      },
      "source": [
        "#### Depency between features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFwQjeEzP63o"
      },
      "outputs": [],
      "source": [
        "# Define the threshold for significance (for example, 0.05)\n",
        "alpha = 0.05\n",
        "\n",
        "# Define an empty list to store the results\n",
        "result = []\n",
        "\n",
        "for cat_feature1 in categorical_features:\n",
        "    for cat_feature2 in categorical_features:\n",
        "        if cat_feature1 != cat_feature2:\n",
        "            contingency_table = pd.crosstab(traindf_dtypes_outlier_corr[cat_feature1], traindf_dtypes_outlier_corr[cat_feature2])\n",
        "            chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "            # Store only significant correlations in the result list\n",
        "            if p < alpha:\n",
        "                result.append([cat_feature1, cat_feature2, p])\n",
        "\n",
        "# Convert the result list into a DataFrame\n",
        "chi_test_output = pd.DataFrame(result, columns=['var1', 'var2', 'p-value'])\n",
        "\n",
        "# Pivot the DataFrame to create a crosstab-like format\n",
        "pivoted_output = chi_test_output.pivot(index='var1', columns='var2', values='p-value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orBpjd6cQ6ya"
      },
      "outputs": [],
      "source": [
        "# Print the pivoted DataFrame\n",
        "pivoted_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ajyz1PARCx-"
      },
      "outputs": [],
      "source": [
        "for cat_feature1 in categorical_features:\n",
        "    for cat_feature2 in categorical_features:\n",
        "        if cat_feature1 != cat_feature2:\n",
        "            contingency_table = pd.crosstab(traindf_dtypes_outlier_corr[cat_feature1], traindf_dtypes_outlier_corr[cat_feature2])\n",
        "            chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "            print(f\"Features: {cat_feature1} and {cat_feature2}, p-value: {p}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUGgaggTTZbQ"
      },
      "outputs": [],
      "source": [
        "# Output dataframe\n",
        "\n",
        "# traindf_dtypes_outlier_corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDTrGHUgTXf5"
      },
      "source": [
        "## Inconsistency Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vucOqspETW8i"
      },
      "outputs": [],
      "source": [
        "# In this step we will address inconsistencies of the train dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTrZnbHvTny-"
      },
      "outputs": [],
      "source": [
        "traindf.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6big0jmTrGq"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RFTxIIkTsCy"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRMt5pxnTs-W"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5aLADT3WOPD"
      },
      "source": [
        "### Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pI5JHAOT9LD"
      },
      "outputs": [],
      "source": [
        "duplicates = traindf_dtypes_outlier_corr[traindf_dtypes_outlier_corr.duplicated()]\n",
        "print(duplicates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL2BeoBFV4rB"
      },
      "source": [
        "Yet python is considering this rows duplicates, after exploring them, we are going to keep them both because we dont really agree that these two are duplicates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68u-XsRxWU3g"
      },
      "source": [
        "### Negative Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roMHT9rcWZ7I"
      },
      "outputs": [],
      "source": [
        "plot_multiple_boxplots(traindf_dtypes_outlier_corr, metric_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB-lrObOXgiA"
      },
      "outputs": [],
      "source": [
        "# Checking for any negative values\n",
        "negative_values = traindf_dtypes_outlier_corr[metric_features].lt(0).any(1)\n",
        "\n",
        "# Count rows with negative values\n",
        "negative_count = negative_values.sum()\n",
        "print(f\"Number of rows with negative values: {negative_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTVcqluRXij2"
      },
      "source": [
        "No negative values!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzeHCiYHXkE6"
      },
      "source": [
        "### Handling Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo8Yf8d7XsQp"
      },
      "source": [
        "**Delete rows with missing values**: This approach is straightforward but can result in a loss of information. If the amount of missing data is small, this approach may be reasonable.\n",
        "\n",
        "**Impute missing values**: This approach involves replacing missing values with estimated values. Common imputation methods include mean imputation, median imputation, mode imputation, regression imputation, and k-nearest neighbor imputation.\n",
        "\n",
        "**Create a missing value indicator**: This approach involves creating a binary indicator variable that indicates whether a value is missing or not. This approach can be useful in situations where the missingness itself is informative.\n",
        "\n",
        "**Use models that can handle missing values**: Some models, such as decision trees and random forests, can handle missing values directly. In these models, missing values are treated as a separate category and are included in the analysis.\n",
        "\n",
        "**Use domain knowledge to estimate missing values**: In some cases, it may be possible to use domain knowledge to estimate missing values. For example, if you are analyzing data on the height and weight of a population, you may be able to use knowledge of human biology to estimate missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TbWmstSYMxq"
      },
      "outputs": [],
      "source": [
        "# plotting the na values for the different features\n",
        "traindf_dtypes_outlier_corr.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DPRDzg_YP6D"
      },
      "source": [
        "#### Dropping missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlP0R9pSYTWF"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr_dropna = traindf_dtypes_outlier_corr.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgfNJviFYU9L"
      },
      "outputs": [],
      "source": [
        "v = traindf_dtypes_outlier_corr_dropna.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkuvUDkcYWhs"
      },
      "outputs": [],
      "source": [
        "vb = traindf_dtypes_outlier_corr.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvTEA-7QYXzP"
      },
      "outputs": [],
      "source": [
        "print(v / vb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAro5r68Yawb"
      },
      "source": [
        "By dropping all the Nan, we are loosing 20% of the dataset. As we dont want to lose that much data set, we are not following this aproach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQv5rWUiYlXv"
      },
      "source": [
        "#### Filling missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg00qVCJYnYs"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wZ2QGmOYsZh"
      },
      "outputs": [],
      "source": [
        "valdf_dtypes_outlier_corr.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLcHfeOqYtLc"
      },
      "outputs": [],
      "source": [
        "testdf_dtypes_outlier_corr.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3KrefcGY00P"
      },
      "source": [
        "Inputting for Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Sxd1oqLa5Ql"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZa_CktTc1Mb"
      },
      "source": [
        "##### Scalling Min-Max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL6jmnodc5hF"
      },
      "source": [
        "Knowing that using the KNN iputer or any other type of inputation we need to scale the data accordingly, we decided to address the point right here, before the use of KNN for the inputation of the na values on metric features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96e_zsYQc52b"
      },
      "outputs": [],
      "source": [
        "# First we do the fit transform in the train dataset\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Instantiate the scaler\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "# Scale the metric features separately\n",
        "scaled_features = minmax_scaler.fit_transform(traindf_dtypes_outlier_corr[metric_features])\n",
        "\n",
        "# Create a DataFrame from the scaled features\n",
        "scaled_features_df = pd.DataFrame(scaled_features, columns=metric_features, index=traindf_dtypes_outlier_corr.index)\n",
        "\n",
        "# Drop the original metric features from the dataframe\n",
        "traindf_dtypes_outlier_corr = traindf_dtypes_outlier_corr.drop(columns=metric_features)\n",
        "\n",
        "# Merge the scaled features back into the dataframe\n",
        "traindf_dtypes_outlier_corr = pd.concat([traindf_dtypes_outlier_corr, scaled_features_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn6IWHnHc-2B"
      },
      "outputs": [],
      "source": [
        "# Then we apply the transform to the validation and test set so the scale is the same\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Scale the metric features separately\n",
        "scaled_features = minmax_scaler.transform(valdf_dtypes_outlier_corr[metric_features])\n",
        "\n",
        "# Create a DataFrame from the scaled features\n",
        "scaled_features_df = pd.DataFrame(scaled_features, columns=metric_features, index=valdf_dtypes_outlier_corr.index)\n",
        "\n",
        "# Drop the original metric features from the dataframe\n",
        "valdf_dtypes_outlier_corr = valdf_dtypes_outlier_corr.drop(columns=metric_features)\n",
        "\n",
        "# Merge the scaled features back into the dataframe\n",
        "valdf_dtypes_outlier_corr = pd.concat([valdf_dtypes_outlier_corr, scaled_features_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8b1mrYFdAlf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Scale the metric features separately\n",
        "scaled_features = minmax_scaler.transform(testdf_dtypes_outlier_corr[metric_features])\n",
        "\n",
        "# Create a DataFrame from the scaled features\n",
        "scaled_features_df = pd.DataFrame(scaled_features, columns=metric_features, index=testdf_dtypes_outlier_corr.index)\n",
        "\n",
        "# Drop the original metric features from the dataframe\n",
        "testdf_dtypes_outlier_corr = testdf_dtypes_outlier_corr.drop(columns=metric_features)\n",
        "\n",
        "# Merge the scaled features back into the dataframe\n",
        "testdf_dtypes_outlier_corr = pd.concat([testdf_dtypes_outlier_corr, scaled_features_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3T8y5fTdE09"
      },
      "source": [
        "Inputting for Metric Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ow6pttwbdIiS"
      },
      "outputs": [],
      "source": [
        "# Now, we will input the missing values with the KNN Inputer\n",
        "# The rational before on the min-max sclaling applies here:\n",
        "# 1. First we fit_transform in the train set\n",
        "# 2. Than we transform into the validation and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEUlXq7pdOL3"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "\n",
        "# Create a copy of the dataframe\n",
        "df_filled = traindf_dtypes_outlier_corr.copy()\n",
        "\n",
        "# Apply the imputer to the metric features only\n",
        "df_filled[metric_features] = imputer.fit_transform(df_filled[metric_features])\n",
        "\n",
        "# Now replace only the missing values in the original dataframe with those from the filled dataframe\n",
        "for feature in metric_features:\n",
        "    traindf_dtypes_outlier_corr.loc[traindf_dtypes_outlier_corr[feature].isnull(), feature] = df_filled.loc[traindf_dtypes_outlier_corr[feature].isnull(), feature]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIFjosWndmS1"
      },
      "source": [
        "using the KNN inputer from the train set we apply to the validation and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yE9TafQoKId"
      },
      "outputs": [],
      "source": [
        "# Create a copy of the dataframe\n",
        "dfval_filled = valdf_dtypes_outlier_corr.copy()\n",
        "\n",
        "# Apply the imputer to the metric features only\n",
        "dfval_filled[metric_features] = imputer.transform(dfval_filled[metric_features])\n",
        "\n",
        "# Now replace only the missing values in the original dataframe with those from the filled dataframe\n",
        "for feature in metric_features:\n",
        "    valdf_dtypes_outlier_corr.loc[valdf_dtypes_outlier_corr[feature].isnull(), feature] = dfval_filled.loc[valdf_dtypes_outlier_corr[feature].isnull(), feature]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBnvORfteN-Q"
      },
      "outputs": [],
      "source": [
        "# Create a copy of the test dataframe\n",
        "df_test_filled = testdf_dtypes_outlier_corr.copy()\n",
        "\n",
        "# Apply the imputer to the metric features only\n",
        "df_test_filled[metric_features] = imputer.transform(df_test_filled[metric_features])\n",
        "\n",
        "# Now replace only the missing values in the original test dataframe with those from the filled dataframe\n",
        "for feature in metric_features:\n",
        "    testdf_dtypes_outlier_corr.loc[testdf_dtypes_outlier_corr[feature].isnull(), feature] = df_test_filled.loc[testdf_dtypes_outlier_corr[feature].isnull(), feature]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrvmH8imeQdh"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAhrQgr-eRkB"
      },
      "outputs": [],
      "source": [
        "valdf_dtypes_outlier_corr.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsLH8Ng7eS1C"
      },
      "outputs": [],
      "source": [
        "testdf_dtypes_outlier_corr.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BI9itSoZepub"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr = traindf_dtypes_outlier_corr.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAjtoQXSer7b"
      },
      "outputs": [],
      "source": [
        "valdf_dtypes_outlier_corr = valdf_dtypes_outlier_corr.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pPmEwKtesfY"
      },
      "outputs": [],
      "source": [
        "testdf_dtypes_outlier_corr = testdf_dtypes_outlier_corr.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd84BTIPewcH"
      },
      "outputs": [],
      "source": [
        "v = traindf_dtypes_outlier_corr.shape[0]\n",
        "vb = traindf_dtypes_outlier.shape[0]\n",
        "\n",
        "print(v / vb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ogt2JG4zzQaw"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr_incon = traindf_dtypes_outlier_corr.copy()\n",
        "valdf_dtypes_outlier_corr_incon = valdf_dtypes_outlier_corr.copy()\n",
        "testdf_dtypes_outlier_corr_incon = testdf_dtypes_outlier_corr.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6tTSVO-e3HP"
      },
      "source": [
        "Replacing the values with KNN helped us not losing any rows of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suA0T5VTe-c6"
      },
      "source": [
        "# 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpaCeRcVyxoB"
      },
      "source": [
        "### 3.1 Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me37hqUszE6q"
      },
      "source": [
        "For the categorical features we need to proceed to the encoding so we can have only numerical values to input in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O58l0XIDlk0f"
      },
      "outputs": [],
      "source": [
        "print(traindf_dtypes_outlier_corr_incon.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5yHYf8KzIXg"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr_incon_encoded = pd.get_dummies(traindf_dtypes_outlier_corr_incon, columns= categorical_features_enc, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K4QFFWozXdw"
      },
      "outputs": [],
      "source": [
        "valdf_dtypes_outlier_corr_incon_encoded = pd.get_dummies(valdf_dtypes_outlier_corr_incon, columns=categorical_features_enc, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVf1BbTdzk4Y"
      },
      "outputs": [],
      "source": [
        "testdf_dtypes_outlier_corr_incon_encoded = pd.get_dummies(testdf_dtypes_outlier_corr_incon, columns=categorical_features_enc, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNTX0n8D6Ps9"
      },
      "outputs": [],
      "source": [
        "# We need to use the categorical features encoded and not those before as they were replaced.\n",
        "\n",
        "# Get the encoded columns\n",
        "encoded_columns = traindf_dtypes_outlier_corr_incon_encoded.columns.tolist()\n",
        "\n",
        "# Get the original columns\n",
        "original_columns = traindf_dtypes_outlier_corr_incon.columns.tolist()\n",
        "\n",
        "# Get the categorical_features_encoded - substitution of the previous categorical_features\n",
        "categorical_features_encoded = [col for col in encoded_columns if col not in original_columns]\n",
        "\n",
        "print(\"Encoded Categorical Features:\")\n",
        "for feature in categorical_features_encoded:\n",
        "    print(feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZinQt4y6W_D"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr_incon_encoded.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76FRYm8v6bM_"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr_incon_encoded.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBNLkqP06hXe"
      },
      "source": [
        "### 3.2 Validating the datasets for modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kePFzKbH6i5q"
      },
      "outputs": [],
      "source": [
        "# Checking if all the names are in the corrected order and aligned\n",
        "\n",
        "def check_column_names_match(df1, df2):\n",
        "    # Get the column names of both dataframes\n",
        "    df1_columns = set(df1.columns)\n",
        "    df2_columns = set(df2.columns)\n",
        "\n",
        "    # Find columns that exist in one dataframe but not in the other\n",
        "    columns_only_in_df1 = df1_columns - df2_columns\n",
        "    columns_only_in_df2 = df2_columns - df1_columns\n",
        "\n",
        "    if columns_only_in_df1:\n",
        "        print(\"Columns present in traind_ but not in testdf:\", columns_only_in_df1)\n",
        "\n",
        "    if columns_only_in_df2:\n",
        "        print(\"Columns present in testdf but not in traind_:\", columns_only_in_df2)\n",
        "\n",
        "    if not columns_only_in_df1 and not columns_only_in_df2:\n",
        "        print(\"Column names match!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZYMmc5A6qhC"
      },
      "outputs": [],
      "source": [
        "check_column_names_match(traindf_dtypes_outlier_corr_incon_encoded, testdf_dtypes_outlier_corr_incon_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcJ1-iaDTJAf"
      },
      "outputs": [],
      "source": [
        "# Drop columns starting with \"Interval of age\" from train and validation datasets\n",
        "traindf_dtypes_outlier_corr_incon_encoded = traindf_dtypes_outlier_corr_incon_encoded.drop(columns=traindf_dtypes_outlier_corr_incon_encoded.filter(regex='^Interval of age').columns)\n",
        "valdf_dtypes_outlier_corr_incon_encoded = valdf_dtypes_outlier_corr_incon_encoded.drop(columns=valdf_dtypes_outlier_corr_incon_encoded.filter(regex='^Interval of age').columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCq3S1ZH6rnV"
      },
      "outputs": [],
      "source": [
        "check_column_names_match(traindf_dtypes_outlier_corr_incon_encoded, valdf_dtypes_outlier_corr_incon_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_lLs0EkBRz2"
      },
      "outputs": [],
      "source": [
        "traindf_dtypes_outlier_corr_incon_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHFXQVqptBC9"
      },
      "outputs": [],
      "source": [
        "# Make copies of the original DataFrames\n",
        "traindf_dtypes_outlier_corr_incon_encoded_fs = traindf_dtypes_outlier_corr_incon_encoded.copy()\n",
        "valdf_dtypes_outlier_corr_incon_encoded_fs = valdf_dtypes_outlier_corr_incon_encoded.copy()\n",
        "testdf_dtypes_outlier_corr_incon_encoded_fs = testdf_dtypes_outlier_corr_incon_encoded.copy()\n",
        "\n",
        "# Define columns to exclude\n",
        "columns_to_exclude = ['name', 'title', 'date_of_birth','city','country']\n",
        "\n",
        "# Filter out columns that actually exist in the DataFrame\n",
        "columns_to_exclude_train = [col for col in columns_to_exclude if col in traindf_dtypes_outlier_corr_incon_encoded_fs.columns]\n",
        "columns_to_exclude_val = [col for col in columns_to_exclude if col in valdf_dtypes_outlier_corr_incon_encoded_fs.columns]\n",
        "columns_to_exclude_test = [col for col in columns_to_exclude if col in testdf_dtypes_outlier_corr_incon_encoded_fs.columns]\n",
        "\n",
        "# Drop the specified columns\n",
        "traindf_dtypes_outlier_corr_incon_encoded_fs.drop(columns=columns_to_exclude_train, inplace=True)\n",
        "valdf_dtypes_outlier_corr_incon_encoded_fs.drop(columns=columns_to_exclude_val, inplace=True)\n",
        "testdf_dtypes_outlier_corr_incon_encoded_fs.drop(columns=columns_to_exclude_test, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vv13f5s63Iw"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZZHTd2B69zk"
      },
      "source": [
        "### 3.3 Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41KPHXXn6-yk"
      },
      "outputs": [],
      "source": [
        "# Splitting the target features from all the other features for the model inputation\n",
        "\n",
        "X_train = traindf_dtypes_outlier_corr_incon_encoded_fs.drop(columns=['lifestyle_type'])\n",
        "y_train = traindf_dtypes_outlier_corr_incon_encoded_fs['lifestyle_type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZPby_Lz7HI6"
      },
      "outputs": [],
      "source": [
        "X_val = valdf_dtypes_outlier_corr_incon_encoded_fs.drop(columns=['lifestyle_type'])\n",
        "y_val = valdf_dtypes_outlier_corr_incon_encoded_fs['lifestyle_type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAIB6hi67LBB"
      },
      "outputs": [],
      "source": [
        "testdf = testdf_dtypes_outlier_corr_incon_encoded_fs.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQCWaH1j7hgv"
      },
      "source": [
        "### 3.4 Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH5zXLjx72j1"
      },
      "source": [
        "Because some of the features after the preprocessing might not be totally required we will use different approaches for the feature selection part.\n",
        "\n",
        "1st we will use the RFE with Logistic Regression.\n",
        "\n",
        "2nd we will use the RFE with the Random Forest Classifier.\n",
        "\n",
        "3rd we will use the NerualNetwork to explore the feature selection.\n",
        "\n",
        "---\n",
        "\n",
        "Each final subset of columns based on the different methods will be indicated as LR, RFC and MLP for the specific models applied for the feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99jEw__A6OL2"
      },
      "source": [
        "#### RFE with Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpn_TgSU73Ht"
      },
      "outputs": [],
      "source": [
        "# the following RFE formula give us the final features to keep and to introduce in the model. Those that are strictly relevant when using this specific approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft9VlpCK74u8"
      },
      "outputs": [],
      "source": [
        "# Number of features to keep\n",
        "nof_list=np.arange(2,X_train.shape[1])\n",
        "high_score=0\n",
        "# Variable to store the optimum features\n",
        "nof=0\n",
        "\n",
        "#list of scores\n",
        "score_list =[]\n",
        "\n",
        "for n in range(len(nof_list)):\n",
        "    model = LogisticRegression()\n",
        "\n",
        "    #create instance of RFE\n",
        "    rfe = RFE(model,n_features_to_select = nof_list[n])\n",
        "\n",
        "    #fit RFE to training data\n",
        "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
        "\n",
        "    #Apply the same RFE transformation to the test data\n",
        "    X_val_rfe = rfe.transform(X_val)\n",
        "\n",
        "    #Create and train instance of Logistic Regression\n",
        "    model.fit(X_train_rfe,y_train)\n",
        "\n",
        "    #predict\n",
        "    y_pred = model.predict(X_val_rfe)\n",
        "\n",
        "    #store f1score in variable\n",
        "    f_score = f1_score(y_val, y_pred, average= \"weighted\")\n",
        "\n",
        "    score_list.append(f_score)\n",
        "\n",
        "    #compare against previous best performance\n",
        "    if(f_score > high_score):\n",
        "        high_score = f_score\n",
        "        nof = nof_list[n]\n",
        "print(\"Optimum number of features: %d\" %nof)\n",
        "print(\"Score with %d features: %f\" % (nof, high_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RI3s4b98Ci1"
      },
      "outputs": [],
      "source": [
        "'''rfe = traindf_dtypes_outlier_corr_incon_encoded_fs_age\n",
        "Optimum number of features: 13\n",
        "Score with 13 features: 0.638124'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h7dovJq8iqb"
      },
      "outputs": [],
      "source": [
        "#fit RFE to your training data - metric features only\n",
        "X_rfe = rfe.fit_transform(X = X_train, y = y_train)\n",
        "\n",
        "# Create an object `selected_features` that will shows which features to keep and which features to throw away\n",
        "selected_features_lr = pd.Series(rfe.support_, index = X_train.columns)\n",
        "selected_features_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsJcqH2iUi5u"
      },
      "outputs": [],
      "source": [
        "# Get the features that were selected as important (i.e., have a value of True)\n",
        "true_features = selected_features_lr[selected_features_lr].index.tolist()\n",
        "\n",
        "# Get the features that are part of the categorical features and should always be kept\n",
        "#categorical_features_to_keep = [feature for feature in categorical_features_encoded if feature not in true_features]\n",
        "\n",
        "# Combine the two lists to get the final list of features to keep\n",
        "features_to_keep_lr = true_features + categorical_features_to_keep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0TPuRAJUmMv"
      },
      "outputs": [],
      "source": [
        "features_to_keep_lr = ['last_year_avg_monthly_charity_donations','environmental_awareness_rating','financial_wellness_index','investment_portfolio_value','investments_risk_appetite','investments_risk_tolerance','tech_savviness_score','social_media_influence_score','entertainment_engagement_factor','avg_monthly_entertainment_expenses','avg_weekly_exercise_hours','health_consciousness_rating','age']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLFNu5lAVUag"
      },
      "outputs": [],
      "source": [
        "# defining the new dataframe name for the dataframe that will keep only the features selected by the RFE Logisti Regression\n",
        "X_train_featureSelected_lr = X_train[features_to_keep_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enXaqhptVVl7"
      },
      "outputs": [],
      "source": [
        "X_val_featureSelected_lr = X_val[features_to_keep_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e5bXfOGVW8G"
      },
      "outputs": [],
      "source": [
        "testdf_featureSelected_lr = testdf[features_to_keep_lr]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OYgEaMM6UQ3"
      },
      "source": [
        "#### RFE with RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFAczWQN6Yfy"
      },
      "outputs": [],
      "source": [
        "# Train the random forest model to get feature importances\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances and sort them\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Try different numbers of top features\n",
        "nof_list = np.arange(2, X_train.shape[1], step=5)  # Adjust step size for fewer iterations\n",
        "high_score = 0\n",
        "nof = 0\n",
        "score_list = []\n",
        "\n",
        "for n in nof_list:\n",
        "    selected_features = indices[:n]\n",
        "\n",
        "    X_train_selected = X_train.iloc[:, selected_features]\n",
        "    X_val_selected = X_val.iloc[:, selected_features]\n",
        "\n",
        "    # Train and predict using the same RandomForestClassifier\n",
        "    model.fit(X_train_selected, y_train)\n",
        "    y_pred = model.predict(X_val_selected)\n",
        "\n",
        "    f_score = f1_score(y_val, y_pred, average=\"weighted\")\n",
        "    score_list.append(f_score)\n",
        "\n",
        "    if f_score > high_score:\n",
        "        high_score = f_score\n",
        "        nof = n\n",
        "\n",
        "print(\"Optimum number of features: %d\" % nof)\n",
        "print(\"Score with %d features: %f\" % (nof, high_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYPAbctpt100"
      },
      "outputs": [],
      "source": [
        "'''Optimum number of features: 12\n",
        "Score with 12 features: 0.0.775521'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbxlwM9bt5rT"
      },
      "outputs": [],
      "source": [
        "rfe = RFE(estimator = RandomForestClassifier(), n_features_to_select = nof)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLSNIX0Vt8hd"
      },
      "outputs": [],
      "source": [
        "#fit RFE to your training data - metric features only\n",
        "X_rfe = rfe.fit_transform(X = X_train, y = y_train)\n",
        "\n",
        "# Create an object `selected_features` that will shows which features to keep and which features to throw away\n",
        "selected_features_rfc = pd.Series(rfe.support_, index = X_train.columns)\n",
        "selected_features_rfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VWnuwoRuAVq"
      },
      "outputs": [],
      "source": [
        "# Get the features that were selected as important (i.e., have a value of True)\n",
        "true_features_rfc = selected_features_rfc[selected_features_rfc].index.tolist()\n",
        "\n",
        "# Get the features that are part of the categorical features and should always be kept\n",
        "#categorical_features_to_keep_rfc = [feature for feature in categorical_features_encoded if feature not in true_features_rfc]\n",
        "\n",
        "# Combine the two lists to get the final list of features to keep\n",
        "features_to_keep_rfc = true_features_rfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeEnliicuIBR"
      },
      "outputs": [],
      "source": [
        "features_to_keep_rfc = ['environmental_awareness_rating',\n",
        " 'financial_wellness_index',\n",
        " 'investment_portfolio_value',\n",
        " 'investments_risk_appetite',\n",
        " 'investments_risk_tolerance',\n",
        " 'tech_savviness_score',\n",
        " 'social_media_influence_score',\n",
        " 'entertainment_engagement_factor',\n",
        " 'avg_monthly_entertainment_expenses',\n",
        " 'avg_weekly_exercise_hours',\n",
        " 'health_consciousness_rating',\n",
        " 'age']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_etAPEgw3Jw"
      },
      "outputs": [],
      "source": [
        "X_train_featureSelected_rfc = X_train[features_to_keep_rfc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWk6LyeP0CZm"
      },
      "outputs": [],
      "source": [
        "X_val_featureSelected_rfc = X_val[features_to_keep_rfc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRNZA3Yx0EAL"
      },
      "outputs": [],
      "source": [
        "testdf_featureSelected_rfc = testdf[features_to_keep_rfc]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qThPHewNsEcZ"
      },
      "source": [
        "#### Feature Selection with Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPkofOEKsUmJ"
      },
      "outputs": [],
      "source": [
        "# Number of features to keep\n",
        "nof_list=np.arange(2,X_train.shape[1])\n",
        "high_score=0\n",
        "# Variable to store the optimum features\n",
        "nof=0\n",
        "#list of scores\n",
        "score_list =[]\n",
        "\n",
        "for n in nof_list:\n",
        "    #create instance of SelectKBest\n",
        "    selector = SelectKBest(score_func=f_classif, k=n)\n",
        "\n",
        "    #fit to training data\n",
        "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "\n",
        "    #apply the transformation to the test data\n",
        "    X_val_selected = selector.transform(X_val)\n",
        "\n",
        "    #Create and train instance of MLPClassifier\n",
        "    model = MLPClassifier(max_iter=1000) # increase max_iter if needed\n",
        "    model.fit(X_train_selected, y_train)\n",
        "\n",
        "    #predict\n",
        "    y_pred = model.predict(X_val_selected)\n",
        "\n",
        "    #store f1score in variable\n",
        "    f_score = f1_score(y_val, y_pred, average=\"weighted\")\n",
        "\n",
        "    score_list.append(f_score)\n",
        "\n",
        "    #compare against previous best performance\n",
        "    if(f_score > high_score):\n",
        "        high_score = f_score\n",
        "        nof = n\n",
        "print(\"Optimum number of features: %d\" %nof)\n",
        "print(\"Score with %d features: %f\" % (nof, high_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1nArhNb00Mk"
      },
      "outputs": [],
      "source": [
        "'''Optimum number of features: 12\n",
        "Score with 12 features: 0.781824'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUzGwBfVVqFj"
      },
      "outputs": [],
      "source": [
        "#fit RFE to your training data - metric features only\n",
        "X_rfe = rfe.fit_transform(X = X_train, y = y_train)\n",
        "\n",
        "# Create an object `selected_features` that will shows which features to keep and which features to throw away\n",
        "selected_features_mlp = pd.Series(rfe.support_, index = X_train.columns)\n",
        "selected_features_mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZb1RuaF073N"
      },
      "outputs": [],
      "source": [
        "selected_features_mlp:['environmental_awareness_rating',\n",
        " 'financial_wellness_index',\n",
        " 'investment_portfolio_value',\n",
        " 'investments_risk_appetite',\n",
        " 'investments_risk_tolerance',\n",
        " 'tech_savviness_score',\n",
        " 'social_media_influence_score',\n",
        " 'entertainment_engagement_factor',\n",
        " 'avg_monthly_entertainment_expenses',\n",
        " 'avg_weekly_exercise_hours',\n",
        " 'health_consciousness_rating',\n",
        " 'age']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c44By_L1El7"
      },
      "outputs": [],
      "source": [
        "# Combine the two lists to get the final list of features to keep\n",
        "features_to_keep_mlp = selected_features_mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJuR3E-E1BtE"
      },
      "outputs": [],
      "source": [
        "features_to_keep_mlp = ['last_year_avg_monthly_charity_donations',\n",
        " 'environmental_awareness_rating',\n",
        " 'financial_wellness_index',\n",
        " 'investment_portfolio_value',\n",
        " 'investments_risk_appetite',\n",
        " 'investments_risk_tolerance',\n",
        " 'tech_savviness_score',\n",
        " 'social_media_influence_score',\n",
        " 'entertainment_engagement_factor',\n",
        " 'avg_monthly_entertainment_expenses',\n",
        " 'avg_weekly_exercise_hours',\n",
        " 'health_consciousness_rating',\n",
        " 'age']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fythExsL1Jqm"
      },
      "outputs": [],
      "source": [
        "X_train_featureSelected_mlp = X_train[features_to_keep_mlp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6kagiRc1Lxp"
      },
      "outputs": [],
      "source": [
        "X_val_featureSelected_mlp = X_val[features_to_keep_mlp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClVxr6BN1OXG"
      },
      "outputs": [],
      "source": [
        "testdf_featureSelected_mlp = testdf[features_to_keep_mlp]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKnXoNMq1SAW"
      },
      "source": [
        "#### Analzing the Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ8-p7oD1S4o"
      },
      "outputs": [],
      "source": [
        "# Convert your lists to sets\n",
        "set_features_lr = set(features_to_keep_lr)\n",
        "set_features_rfc = set(features_to_keep_rfc)\n",
        "set_features_mlp = set(features_to_keep_mlp)\n",
        "\n",
        "# Find common features among all three methods\n",
        "common_features = set_features_lr.intersection(set_features_rfc, set_features_mlp)\n",
        "print(f\"Common features selected by all methods: {common_features}\")\n",
        "\n",
        "# Find features unique to each method\n",
        "unique_features_lr = set_features_lr.difference(set_features_rfc, set_features_mlp)\n",
        "unique_features_rfc = set_features_rfc.difference(set_features_lr, set_features_mlp)\n",
        "unique_features_mlp = set_features_mlp.difference(set_features_lr, set_features_rfc)\n",
        "\n",
        "print(f\"Features unique to Logistic Regression: {unique_features_lr}\")\n",
        "print(f\"Features unique to Random Forest Classifier: {unique_features_rfc}\")\n",
        "print(f\"Features unique to MLP: {unique_features_mlp}\")\n",
        "\n",
        "# Find features that were selected by at least two methods\n",
        "common_features_lr_rfc = set_features_lr.intersection(set_features_rfc)\n",
        "common_features_lr_mlp = set_features_lr.intersection(set_features_mlp)\n",
        "common_features_rfc_mlp = set_features_rfc.intersection(set_features_mlp)\n",
        "\n",
        "print(f\"Features selected by both Logistic Regression and Random Forest Classifier: {common_features_lr_rfc}\")\n",
        "print(f\"Features selected by both Logistic Regression and MLP: {common_features_lr_mlp}\")\n",
        "print(f\"Features selected by both Random Forest Classifier and MLP: {common_features_rfc_mlp}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeJxtqFf1e6M"
      },
      "source": [
        "## 3.5 Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcKmjUU61qOR"
      },
      "source": [
        "We will approach the cross validation to check which of the model this method indicate us, however we use cross validation before in each model in order to produce the best outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtPVk04F1s3x"
      },
      "source": [
        "### Stratified K-Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3uc42xi29dJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DuJ-V_k1iBv"
      },
      "outputs": [],
      "source": [
        "classifiers = {\n",
        "    'Logistic Regression': (\n",
        "        LogisticRegression(max_iter=10000),\n",
        "        [\n",
        "            {'C': np.logspace(-2, 2, 5), 'penalty': ['l1'], 'solver': ['liblinear']},\n",
        "            {'C': np.logspace(-2, 2, 5), 'penalty': ['l2'], 'solver': ['lbfgs']}\n",
        "        ]\n",
        "    ),\n",
        "    'Random Forest': (\n",
        "        RandomForestClassifier(),\n",
        "        {\n",
        "            'n_estimators': [50, 100], 'max_depth': [None, 10, 20], 'min_samples_split': [3, 5, 7]}\n",
        "        ),\n",
        "    'Decision Tree': (\n",
        "        DecisionTreeClassifier(),\n",
        "        {\n",
        "            'max_depth': [None, 10, 20], 'criterion': ['gini']}\n",
        "    ),\n",
        "    'KNN': (\n",
        "        KNeighborsClassifier(),\n",
        "        {\n",
        "            'n_neighbors': [3, 5], 'weights': ['uniform']}\n",
        "    )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32ibi9epvFXJ"
      },
      "outputs": [],
      "source": [
        "# the strategy to cross validation\n",
        "cv_strategy = StratifiedKFold(n_splits=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92sTdQq-3Cdy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
        "\n",
        "# defining the measure functions\n",
        "scoring = {\n",
        "    'Accuracy': make_scorer(accuracy_score),\n",
        "    'F1': make_scorer(f1_score, average='weighted')\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFGScBp13H24"
      },
      "source": [
        "#### with Feature Selection LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF1ppkW63Jgj"
      },
      "outputs": [],
      "source": [
        "'''# Iterate over the classifiers, perform hyperparameter tuning using grid search, and cross-validation\n",
        "\n",
        "for classifier_name, (model, parameters) in classifiers.items():\n",
        "    gs_clf = GridSearchCV(model, parameters, cv=cv_strategy, scoring=scoring, refit='F1', return_train_score=True)\n",
        "    gs_clf.fit(X_train_featureSelected_lr, y_train)\n",
        "    print(f\"Best parameters for {classifier_name} are {gs_clf.best_params_}\")\n",
        "    print(f\"Best score for {classifier_name} is {gs_clf.best_score_}\")\n",
        "    print(\"-----------------------\\n\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2D-kYe8PnjE"
      },
      "outputs": [],
      "source": [
        "'''Best parameters for Logistic Regression are {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
        "Best score for Logistic Regression is 0.6389079933682763\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Random Forest are {'max_depth': None, 'min_samples_split': 3, 'n_estimators': 100}\n",
        "Best score for Random Forest is 0.7753435758777119\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Decision Tree are {'criterion': 'gini', 'max_depth': 10}\n",
        "Best score for Decision Tree is 0.7134352393085869\n",
        "-----------------------\n",
        "\n",
        "Best parameters for KNN are {'n_neighbors': 5, 'weights': 'uniform'}\n",
        "Best score for KNN is 0.6771021018808263\n",
        "-----------------------'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2VQNhn-PrBV"
      },
      "source": [
        "#### with Feature Selection RFC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxnGezhyPsg6"
      },
      "outputs": [],
      "source": [
        "'''# Iterate over the classifiers, perform hyperparameter tuning using grid search, and cross-validation\n",
        "\n",
        "for classifier_name, (model, parameters) in classifiers.items():\n",
        "    gs_clf = GridSearchCV(model, parameters, cv=cv_strategy, scoring=scoring, refit='F1', return_train_score=True)\n",
        "    gs_clf.fit(X_train_featureSelected_rfc, y_train)\n",
        "    print(f\"Best parameters for {classifier_name} are {gs_clf.best_params_}\")\n",
        "    print(f\"Best score for {classifier_name} is {gs_clf.best_score_}\")\n",
        "    print(\"-----------------------\\n\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmR34uNwPyK3"
      },
      "outputs": [],
      "source": [
        "'''Best parameters for Logistic Regression are {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
        "Best score for Logistic Regression is 0.6363930801119528\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Random Forest are {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
        "Best score for Random Forest is 0.7717204338689451\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Decision Tree are {'criterion': 'gini', 'max_depth': 10}\n",
        "Best score for Decision Tree is 0.7115679782401878\n",
        "-----------------------\n",
        "\n",
        "Best parameters for KNN are {'n_neighbors': 5, 'weights': 'uniform'}\n",
        "Best score for KNN is 0.6750837745504914\n",
        "-----------------------\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWSZGdcMP3v5"
      },
      "source": [
        "#### with Feature Selection MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3w8xNG3P55i"
      },
      "outputs": [],
      "source": [
        "# Iterate over the classifiers, perform hyperparameter tuning using grid search, and cross-validation\n",
        "\n",
        "for classifier_name, (model, parameters) in classifiers.items():\n",
        "    gs_clf = GridSearchCV(model, parameters, cv=cv_strategy, scoring=scoring, refit='F1', return_train_score=True)\n",
        "    gs_clf.fit(X_train_featureSelected_mlp, y_train)\n",
        "    print(f\"Best parameters for {classifier_name} are {gs_clf.best_params_}\")\n",
        "    print(f\"Best score for {classifier_name} is {gs_clf.best_score_}\")\n",
        "    print(\"-----------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51NEG33DQBnA"
      },
      "outputs": [],
      "source": [
        "'''Best parameters for Logistic Regression are {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
        "Best score for Logistic Regression is 0.6389079933682763\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Random Forest are {'max_depth': None, 'min_samples_split': 7, 'n_estimators': 100}\n",
        "Best score for Random Forest is 0.774980665884699\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Decision Tree are {'criterion': 'gini', 'max_depth': 10}\n",
        "Best score for Decision Tree is 0.7135939938067647\n",
        "-----------------------\n",
        "\n",
        "Best parameters for KNN are {'n_neighbors': 5, 'weights': 'uniform'}\n",
        "Best score for KNN is 0.6771021018808263\n",
        "-----------------------'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O8keWamQB6D"
      },
      "source": [
        "### Traditional K-Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9P4OWSkQMlh"
      },
      "outputs": [],
      "source": [
        " from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIq-s6aIQDhH"
      },
      "outputs": [],
      "source": [
        "# The definition of the classifiers to be used and approach\n",
        "\n",
        "classifiers = {\n",
        "    'Logistic Regression': (\n",
        "        LogisticRegression(max_iter=10000),\n",
        "        [\n",
        "            {'C': np.logspace(-2, 2, 5), 'penalty': ['l1'], 'solver': ['liblinear']},\n",
        "            {'C': np.logspace(-2, 2, 5), 'penalty': ['l2'], 'solver': ['lbfgs']}\n",
        "        ]\n",
        "    ),\n",
        "    'Random Forest': (\n",
        "        RandomForestClassifier(),\n",
        "        {\n",
        "            'n_estimators': [50, 100], 'max_depth': [None, 10, 20], 'min_samples_split': [3, 5, 7]}\n",
        "        ),\n",
        "    'Decision Tree': (\n",
        "        DecisionTreeClassifier(),\n",
        "        {\n",
        "            'max_depth': [None, 10, 20], 'criterion': ['gini']}\n",
        "    ),\n",
        "    'KNN': (\n",
        "        KNeighborsClassifier(),\n",
        "        {\n",
        "            'n_neighbors': [3, 5], 'weights': ['uniform']}\n",
        "    )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xut5LiHEQQX5"
      },
      "outputs": [],
      "source": [
        "# the strategy to cross validation\n",
        "cvs_strategy = KFold(n_splits=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l2DdwmgQRL6"
      },
      "outputs": [],
      "source": [
        "# defining the measure functions\n",
        "scoring = {\n",
        "    'Accuracy': make_scorer(accuracy_score),\n",
        "    'F1': make_scorer(f1_score, average='weighted')\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmHbwzByRUOz"
      },
      "source": [
        "#### with Feature Selection LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T4nW0spRVtV"
      },
      "outputs": [],
      "source": [
        "'''# Iterate over the classifiers, perform hyperparameter tuning using grid search, and cross-validation\n",
        "\n",
        "for classifier_name, (model, parameters) in classifiers.items():\n",
        "    gs_clf = GridSearchCV(model, parameters, cv=cvs_strategy, scoring=scoring, refit='F1', return_train_score=True)\n",
        "    gs_clf.fit(X_train_featureSelected_lr, y_train)\n",
        "    print(f\"Best parameters for {classifier_name} are {gs_clf.best_params_}\")\n",
        "    print(f\"Best score for {classifier_name} is {gs_clf.best_score_}\")\n",
        "    print(\"-----------------------\\n\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WxbO44QRbsP"
      },
      "outputs": [],
      "source": [
        "'''Best parameters for Logistic Regression are {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
        "Best score for Logistic Regression is 0.6389561794062362\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Random Forest are {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
        "Best score for Random Forest is 0.7744894486925247\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Decision Tree are {'criterion': 'gini', 'max_depth': 10}\n",
        "Best score for Decision Tree is 0.7155028736669042\n",
        "-----------------------\n",
        "\n",
        "Best parameters for KNN are {'n_neighbors': 5, 'weights': 'uniform'}\n",
        "Best score for KNN is 0.6772173140686943\n",
        "-----------------------'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc7DWkMJRb-6"
      },
      "source": [
        "#### with Feature Selection RFC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPytUdu7Reda"
      },
      "outputs": [],
      "source": [
        "# Iterate over the classifiers, perform hyperparameter tuning using grid search, and cross-validation\n",
        "\n",
        "for classifier_name, (model, parameters) in classifiers.items():\n",
        "    gs_clf = GridSearchCV(model, parameters, cv=cvs_strategy, scoring=scoring, refit='F1', return_train_score=True)\n",
        "    gs_clf.fit(X_train_featureSelected_rfc, y_train)\n",
        "    print(f\"Best parameters for {classifier_name} are {gs_clf.best_params_}\")\n",
        "    print(f\"Best score for {classifier_name} is {gs_clf.best_score_}\")\n",
        "    print(\"-----------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsEwAjcbWxZr"
      },
      "outputs": [],
      "source": [
        "'''Best parameters for Logistic Regression are {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
        "Best score for Logistic Regression is 0.6364994222429894\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Random Forest are {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
        "Best score for Random Forest is 0.7726886463169531\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Decision Tree are {'criterion': 'gini', 'max_depth': 10}\n",
        "Best score for Decision Tree is 0.7131829334884128\n",
        "-----------------------\n",
        "\n",
        "Best parameters for KNN are {'n_neighbors': 5, 'weights': 'uniform'}\n",
        "Best score for KNN is 0.6751881883992498\n",
        "-----------------------'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpXnj9UURo72"
      },
      "source": [
        "#### with Feature Selection MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qPgUn-vRqh_"
      },
      "outputs": [],
      "source": [
        "# Iterate over the classifiers, perform hyperparameter tuning using grid search, and cross-validation\n",
        "\n",
        "for classifier_name, (model, parameters) in classifiers.items():\n",
        "    gs_clf = GridSearchCV(model, parameters, cv=cvs_strategy, scoring=scoring, refit='F1', return_train_score=True)\n",
        "    gs_clf.fit(X_train_featureSelected_mlp, y_train)\n",
        "    print(f\"Best parameters for {classifier_name} are {gs_clf.best_params_}\")\n",
        "    print(f\"Best score for {classifier_name} is {gs_clf.best_score_}\")\n",
        "    print(\"-----------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE6rKkO-e7rN"
      },
      "outputs": [],
      "source": [
        "'''Best parameters for Logistic Regression are {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
        "Best score for Logistic Regression is 0.6389561794062362\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Random Forest are {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
        "Best score for Random Forest is 0.775204630666269\n",
        "-----------------------\n",
        "\n",
        "Best parameters for Decision Tree are {'criterion': 'gini', 'max_depth': 10}\n",
        "Best score for Decision Tree is 0.7156243887801113\n",
        "-----------------------\n",
        "\n",
        "Best parameters for KNN are {'n_neighbors': 5, 'weights': 'uniform'}\n",
        "Best score for KNN is 0.6772173140686943\n",
        "-----------------------'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvu7J2lLRulS"
      },
      "source": [
        "## 4. Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JinnEFQre0fR"
      },
      "source": [
        "### 4.1 KNN Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVYYT_2sVssU"
      },
      "source": [
        "#### FS with LR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nEVuZwVSJHj"
      },
      "source": [
        "In this section we apprach the different models to be used.\n",
        "\n",
        "Here we will go through each model, and in each, we try by using a normal approach and with the different features selected to check the best outcome in each.\n",
        "\n",
        "**---**\n",
        "\n",
        "For each model we run a hyperparameterization, that will be applied to the best outcome model with the different feature selection approach.\n",
        "\n",
        "\n",
        "**---**\n",
        "\n",
        "The hyper parameterization will be commented so the script runs from the begining till the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5kyIdE6S3m-"
      },
      "source": [
        "On the moddeling we follow always the same approach for consistency\n",
        "\n",
        "1. Pass the model to a variable\n",
        "2. Fit the model into the X_train and the y_train\n",
        "3. Predict the values using the X_val and saving it to a y_pred\n",
        "4. Comparing this y_pred with the existing y_val to address the behavior and performance of the model:\n",
        "    -    4.1 Confusion Matrix\n",
        "    -    4.2 Accuracy\n",
        "    -    4.3 ROC-AUC score\n",
        "    -    4.4 Precision Score\n",
        "    -    4.5 Recall Score\n",
        "    -    4.6 ROC curve\n",
        "5. Make the predicitons on the test set\n",
        "6. Saving those predicition in a variable in a folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkSJ8Wr5R1vv"
      },
      "outputs": [],
      "source": [
        "modelKNN_lr = KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDMkzOveVMFh"
      },
      "outputs": [],
      "source": [
        "modelKNN_lr.fit(X_train_featureSelected_lr, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6Yn13xBVND2"
      },
      "outputs": [],
      "source": [
        "y_pred = modelKNN_lr.predict(X_val_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b2PPkp9VOfV"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maCqy-7BVPUq"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"KNN Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjj9e7NEVQZR"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = modelKNN_lr.predict_proba(X_val_featureSelected_lr)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"KNN ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHKQgBifVRU9"
      },
      "outputs": [],
      "source": [
        "precision = precision_score(y_val, y_pred, average='weighted')\n",
        "print(\"KNN Precision (weighted): \", precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv2-iMGZVSnu"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c62FaeNIVT-M"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZNLkrZwVUzo"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "# Get the predicted probabilities for each class\n",
        "y_pred_prob = modelKNN_lr.predict_proba(X_val_featureSelected_lr)\n",
        "\n",
        "# Binarize the true labels\n",
        "y_val_binarized = label_binarize(y_val, classes=np.unique(y_val))\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "n_classes = len(np.unique(y_val))\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_val_binarized[:, i], y_pred_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for class %d' % (roc_auc[i], i))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for KNN')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufPJ17c9VWTm"
      },
      "outputs": [],
      "source": [
        "modelKNN_lr.score(X_train_featureSelected_lr, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnY0yLbvVXSP"
      },
      "outputs": [],
      "source": [
        "modelKNN_lr.score(X_val_featureSelected_lr, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWuEUf9gVYtF"
      },
      "outputs": [],
      "source": [
        "print(f'F1 Score between the y_test and labels_test: {f1_score(y_val, y_pred, average = \"weighted\"):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWIEcQyoVZvK"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_modelknn_fS_lr = modelKNN_lr.predict(testdf_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHVZFbTfW3xD"
      },
      "outputs": [],
      "source": [
        "# Step 1: Check Lengths\n",
        "print(\"Length of testdf.index:\", len(testdf.index))\n",
        "print(\"Length of test_predictions_modelknn_fS_lr:\", len(test_predictions_modelknn_fS_lr))\n",
        "\n",
        "# Step 3: Create DataFrame\n",
        "if len(testdf.index) == len(test_predictions_modelknn_fS_lr):\n",
        "    modelknn_submission_df_fS_lr = pd.DataFrame({\n",
        "        \"citizen_id\": testdf.index,  # Use the correct index or ID column\n",
        "        \"lifestyle_type\": test_predictions_modelknn_fS_lr\n",
        "    })\n",
        "    print(modelknn_submission_df_fS_lr.head())\n",
        "else:\n",
        "    print(\"Error: Lengths of index and predictions do not match.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRdef-bDVbb9"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "modelknn_submission_df_fS_lr = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_modelknn_fS_lr\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICWFH_UzVfgO"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(modelknn_submission_df_fS_lr, 'modelknn_submission_df_nV_fS_lr', '/content/drive/MyDrive/Data Mining II project/Results')'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5V9cXvpNgq0"
      },
      "outputs": [],
      "source": [
        "#score : 0,67205"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OovwLmlhVoLr"
      },
      "source": [
        "#### FS with RFC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsAR7OLyVw36"
      },
      "outputs": [],
      "source": [
        "modelKNN_rfc = KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0ngTsRpXQEz"
      },
      "outputs": [],
      "source": [
        "modelKNN_rfc.fit(X_train_featureSelected_rfc, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKK4OttaXRYu"
      },
      "outputs": [],
      "source": [
        "y_pred = modelKNN_rfc.predict(X_val_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXsxBBx-XTqy"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzB9WhSqXWMy"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"KNN Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-S5eO8mXuE_"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = modelKNN_rfc.predict_proba(X_val_featureSelected_rfc)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"KNN ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHH5yhdxZM_L"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYrLbKIiZQB0"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOqjHcJRZTx3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "# Get the predicted probabilities for each class\n",
        "y_pred_prob = modelKNN_rfc.predict_proba(X_val_featureSelected_rfc)\n",
        "\n",
        "# Binarize the true labels\n",
        "y_val_binarized = label_binarize(y_val, classes=np.unique(y_val))\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "n_classes = len(np.unique(y_val))\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_val_binarized[:, i], y_pred_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for class %d' % (roc_auc[i], i))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for KNN')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmyWl7yRZ2-0"
      },
      "outputs": [],
      "source": [
        "modelKNN_rfc.score(X_train_featureSelected_rfc, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JN8vKgYZ97w"
      },
      "outputs": [],
      "source": [
        "modelKNN_rfc.score(X_val_featureSelected_rfc, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PweDiJ1OaEti"
      },
      "outputs": [],
      "source": [
        "print(f'F1 Score between the y_test and labels_test: {f1_score(y_val, y_pred, average = \"weighted\"):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq5tjJ6oaMsP"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_modelknn_fS_rfc = modelKNN_rfc.predict(testdf_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G4soZqGaPfr"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "modelknn_submission_df_fS_rfc = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_modelknn_fS_rfc\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P06-aHXaaUTv"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(modelknn_submission_df_fS_rfc, 'modelknn_submission_df_nV_fS_rfc', '/content/drive/MyDrive/Data Mining II project/Results')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ypzscqg3Ni2S"
      },
      "outputs": [],
      "source": [
        "# score: 0,67278"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS3v7kzCby_k"
      },
      "source": [
        "#### Hyperparameterization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4BdUmDNVxY2"
      },
      "source": [
        "Knowing that the KNN model with the best performance was the one using the feature selected based logistic regression, so we are using X_train_featureSelected_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtWPDUkTVl5Z"
      },
      "outputs": [],
      "source": [
        "'''# Parameter distribution for RandomizedSearch\n",
        "param_dist_knn = {\n",
        "    'n_neighbors': randint(1, 30),\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "random_search_knn = RandomizedSearchCV(KNeighborsClassifier(), param_dist_knn, n_iter=100, cv=5)\n",
        "random_search_knn.fit(X_train_featureSelected_rfc, y_train)\n",
        "print(\"RandomizedSearchCV - Best parameters for KNN: \", random_search_knn.best_params_)\n",
        "print(\"RandomizedSearchCV - Best score for KNN: \", random_search_knn.best_score_)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjDP1grGkcNz"
      },
      "source": [
        "#### Model w/ Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jjf5yWL7WC22"
      },
      "outputs": [],
      "source": [
        "'''modelKNN_hp = KNeighborsClassifier(n_neighbors=24, weights='uniform')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccf1Lg7PWEOZ"
      },
      "outputs": [],
      "source": [
        "'''modelKNN_hp.fit(X_train_featureSelected_rfc, y_train)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riN_xT5fWF7x"
      },
      "outputs": [],
      "source": [
        "'''y_pred = modelKNN_hp.predict(X_val_featureSelected_rfc)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFftdGnFWJHg"
      },
      "outputs": [],
      "source": [
        "'''confusion_matrix(y_val, y_pred)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu5Qx1RzWKXr"
      },
      "outputs": [],
      "source": [
        "'''accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"KNN Accuracy: \", accuracy)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0NBqMeeWLUg"
      },
      "outputs": [],
      "source": [
        "'''y_pred_prob = modelKNN_hp.predict_proba(X_val_featureSelected_rfc)[:, 1]\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"KNN ROC-AUC: \", roc_auc)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtbRYUtoWX_n"
      },
      "outputs": [],
      "source": [
        "'''precision_score(y_val, y_pred)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CeLho94WaPO"
      },
      "outputs": [],
      "source": [
        "'''recall_score(y_val, y_pred)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WugQo6B0WbYG"
      },
      "outputs": [],
      "source": [
        "'''print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PytfHq-AWctQ"
      },
      "outputs": [],
      "source": [
        "'''fpr, tpr, thresholds = roc_curve(y_val, y_pred_prob)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr, label='KNN')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('KNN ROC Curve')\n",
        "plt.show()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pciCNPNbWeDR"
      },
      "outputs": [],
      "source": [
        "'''modelKNN_hp.score(X_train_featureSelected_lr, y_train)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJTF73KoWfFM"
      },
      "outputs": [],
      "source": [
        "'''modelKNN_hp.score(X_val_featureSelected_lr, y_val)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKgYK8pIWhOZ"
      },
      "outputs": [],
      "source": [
        "'''print(f'F1 Score between the y_test and labels_test: {f1_score(y_val, y_pred):.3f}')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72vb7zWCWqxD"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "'''test_predictions_modelknn_hp = modelKNN_hp.predict(testdf_featureSelected_lr)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSGMgDwhWris"
      },
      "outputs": [],
      "source": [
        "'''# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "modelknn_submission_df_hp = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_modelknn_hp\n",
        "})'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HDl4i9_WxwB"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(modelknn_submission_df_hp, '/content/drive/MyDrive/Data Mining II project/Results/hpp')'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZhMtnO-kiqE"
      },
      "source": [
        "## 4.2 Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78Vzeqb7knMi"
      },
      "source": [
        "#### FS with LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Tc3YFSCkj49"
      },
      "outputs": [],
      "source": [
        "rfc_model_fs_lr = RandomForestClassifier()\n",
        "rfc_model_fs_lr.fit(X_train_featureSelected_lr, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2woOkX3nlugZ"
      },
      "outputs": [],
      "source": [
        "# predictions to y_pred, using the method `predict()`.\n",
        "\n",
        "y_pred = rfc_model_fs_lr.predict(X_val_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JyYrWz_lwjD"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UDAb31plyXT"
      },
      "outputs": [],
      "source": [
        "# accuracy score for the logistic regression applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Random Forest Classifier Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp7Hr2FEoRio"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = rfc_model_fs_lr.predict_proba(X_val_featureSelected_lr)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"Random Forest Classifie ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocxeD9u6ngrJ"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, average =\"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXYGKSrwnlV_"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average =\"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9iFmsZuoDI-"
      },
      "outputs": [],
      "source": [
        "# Get feature importance\n",
        "importances = rfc_model_fs_lr.feature_importances_\n",
        "\n",
        "# Print them out\n",
        "for feature, importance in zip(X_train_featureSelected_lr.columns, importances):\n",
        "    print(f\"The feature {feature} has an importance of {importance}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZyhhP3voEZB"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_Hq_eSynefO"
      },
      "outputs": [],
      "source": [
        "#fazer plot de ROC_AUC?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44E01tN1oHYU"
      },
      "outputs": [],
      "source": [
        "test_predictions_rfcmodel_fs_lr = rfc_model_fs_lr.predict(testdf_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKmCoWIfpd7F"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "rfcmodel_submission_df_fs_lr = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_rfcmodel_fs_lr\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNL-pxa7rSDv"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(rfcmodel_submission_df_fs_lr, 'rfcmodel_submission_df_nV_fS_lr', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgQlhRsRmVAS"
      },
      "outputs": [],
      "source": [
        "#score de 0,77302"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmoC6GwZrgy2"
      },
      "source": [
        "### FS with RFC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fpg7u6rrhbe"
      },
      "outputs": [],
      "source": [
        "rfc_model_fs_rfc = RandomForestClassifier()\n",
        "rfc_model_fs_rfc.fit(X_train_featureSelected_rfc, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5sKciC1rjM_"
      },
      "outputs": [],
      "source": [
        "# predictions to y_pred, using the method `predict()`.\n",
        "\n",
        "y_pred = rfc_model_fs_rfc.predict(X_val_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ppu_hsRrkaF"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qwqmbW5rluX"
      },
      "outputs": [],
      "source": [
        "# accuracy score for the logistic regression applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Random Forest Classifier Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akndjfWmrmYO"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = rfc_model_fs_rfc.predict_proba(X_val_featureSelected_rfc)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"Random Forest Classifie ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHGoKb2MroB9"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcQEjbGyro6W"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9y-ejz4ruDU"
      },
      "outputs": [],
      "source": [
        "# Get feature importance\n",
        "importances = rfc_model_fs_rfc.feature_importances_\n",
        "\n",
        "# Print them out\n",
        "for feature, importance in zip(X_train_featureSelected_rfc.columns, importances):\n",
        "    print(f\"The feature {feature} has an importance of {importance}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBDJxEdNrvxu"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-nm1payrxGP"
      },
      "outputs": [],
      "source": [
        "# plot de ROC CURVE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIZ6c67asCnV"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_rfcmodel_fs_rfc = rfc_model_fs_rfc.predict(testdf_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "537GZtCxsDdS"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "rfcmodel_submission_df_fs_rfc = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_rfcmodel_fs_rfc\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhH3d1X3sggB"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(rfcmodel_submission_df_fs_rfc, 'rfcmodel_submission_df_nV_fS_rfc', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK_uVdjAmX0w"
      },
      "outputs": [],
      "source": [
        "#score : 0,766672"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_W2saNvW_ON"
      },
      "source": [
        "### Hyperparameterization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StNFTL_gXAHT"
      },
      "source": [
        "Knowing that the RFC model with the best performance was the one using the feature selected based logistic regression, so we are using X_train_featureSelected_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue_Oz_h3W_wU"
      },
      "outputs": [],
      "source": [
        "'''from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [200, 250, 300, 350, 400],\n",
        "    'max_depth': [30, 40, 50, 60],\n",
        "    'min_samples_split': [3, 4, 5, 6, 7, 8, 9, 10]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=param_dist, n_iter=50, cv=5, n_jobs=-1)\n",
        "random_search.fit(X_train_featureSelected_lr, y_train)\n",
        "\n",
        "print(\"Best parameters: \", random_search.best_params_)\n",
        "print(\"Best score: \", random_search.best_score_)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku9_95fQXVAZ"
      },
      "source": [
        "### Model w/ Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-WivC6kXT_b"
      },
      "outputs": [],
      "source": [
        "'''rfc_model_fs_lr_hp = RandomForestClassifier(n_estimators=300, min_samples_split=5, max_depth=50)\n",
        "rfc_model_fs_lr_hp.fit(X_train_featureSelected_lr, y_train)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3--13DDeXal5"
      },
      "outputs": [],
      "source": [
        "'''# predictions to y_pred, using the method `predict()`.\n",
        "\n",
        "y_pred = rfc_model_fs_lr_hp.predict(X_val_featureSelected_lr)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAENr0YBXcWG"
      },
      "outputs": [],
      "source": [
        "'''# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU9Be3KyXdZA"
      },
      "outputs": [],
      "source": [
        "'''# accuracy score for the logistic regression applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Random Forest Classifier Accuracy: \", accuracy)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvjEgVClXeUp"
      },
      "outputs": [],
      "source": [
        "'''y_pred_prob = rfc_model_fs_lr_hp.predict_proba(X_val_featureSelected_lr)[:, 1]\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class = 'ovr')\n",
        "print(\"Random Forest Classifie ROC-AUC: \", roc_auc)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_LY2IKdXjD3"
      },
      "outputs": [],
      "source": [
        "'''precision_score(y_val, y_pred, average = \"weighted\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaI1FemiXl-f"
      },
      "outputs": [],
      "source": [
        "'''recall_score(y_val, y_pred, average = \"weighted\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewmh_m-nXocm"
      },
      "outputs": [],
      "source": [
        "'''# Get feature importance\n",
        "importances = rfc_model_fs_lr_hp.feature_importances_\n",
        "\n",
        "# Print them out\n",
        "for feature, importance in zip(X_train_featureSelected_lr.columns, importances):\n",
        "    print(f\"The feature {feature} has an importance of {importance}\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYETLUMnXrCL"
      },
      "outputs": [],
      "source": [
        "'''print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUXlL4k7Xr_E"
      },
      "outputs": [],
      "source": [
        "'''fpr, tpr, thresholds = roc_curve(y_val, y_pred_prob)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr, label='Random Forest')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Random Forest ROC Curve')\n",
        "plt.show()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UldiKj4iXtJJ"
      },
      "outputs": [],
      "source": [
        "'''# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_rfcmodel_hp_fs_lr = rfc_model_fs_lr_hp.predict(testdf_featureSelected_lr)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRTQQdpmXt9y"
      },
      "outputs": [],
      "source": [
        "'''# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "rfcmodel_hp_submission_df_fs_lr = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_rfcmodel_hp_fs_lr\n",
        "})'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NXACey7Xv1L"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(rfcmodel_hp_submission_df_fs_lr, '/content/drive/MyDrive/Data Mining II project/Results/hpp')'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R18SLvlU544e"
      },
      "source": [
        "## 4.3 Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXnCyeSl58kP"
      },
      "source": [
        "### FS with LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prVQLu_056zC"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCoWEFyt5_D-"
      },
      "outputs": [],
      "source": [
        "# Define the three base models\n",
        "model1 = RandomForestClassifier(n_estimators=300, min_samples_split=5, max_depth=50)\n",
        "model2 = GradientBoostingClassifier(subsample=0.8, n_estimators=100, min_samples_split=2, max_depth=4, learning_rate=0.1)\n",
        "model3 = MLPClassifier(solver='adam', learning_rate='adaptive', hidden_layer_sizes=(50, 100, 50), alpha=0.05, activation='tanh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsmclJgl6BbJ"
      },
      "outputs": [],
      "source": [
        "# Combine the models into an ensemble\n",
        "ensemble_fS_lr = VotingClassifier(estimators=[('rf', model1), ('gb', model2), ('lr', model3)])\n",
        "\n",
        "# Fit the ensemble model\n",
        "ensemble_fS_lr.fit(X_train_featureSelected_lr, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuuN-rb16Chw"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = ensemble_fS_lr.predict(X_val_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cilUJWr6D0w"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkM7IvYi6X3i"
      },
      "outputs": [],
      "source": [
        "# accuracy score for the logistic regression applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Ensemble: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EASoI7gX6Ye3"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq4tbaVV6ZBW"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NokufbFr6Zzs"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzhd-hpE6bi4"
      },
      "outputs": [],
      "source": [
        "#plot de ROC CURVE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFw8hhDY6c7X"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_ensemblemodel_fs_lr = ensemble_fS_lr.predict(testdf_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5RcBz2e6dYY"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "ensemblemodel_submission_df_fs_lr = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_ensemblemodel_fs_lr\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Taf2usXe6kVV"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(ensemblemodel_submission_df_fs_lr, 'ensemblemodel_submission_df_fs_lr', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz6ZOceLmF_z"
      },
      "outputs": [],
      "source": [
        "#score de 0,77779"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW8p_Tfh-FBy"
      },
      "source": [
        "### FS with RFC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT71Psw5-HC0"
      },
      "outputs": [],
      "source": [
        "# Define the three base models\n",
        "model1 = RandomForestClassifier(n_estimators=300, min_samples_split=5, max_depth=50)\n",
        "model2 = GradientBoostingClassifier(subsample=0.8, n_estimators=100, min_samples_split=2, max_depth=4, learning_rate=0.1)\n",
        "model3 = MLPClassifier(solver='adam', learning_rate='adaptive', hidden_layer_sizes=(50, 100, 50), alpha=0.05, activation='tanh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxC5Og5g-IrW"
      },
      "outputs": [],
      "source": [
        "# Combine the models into an ensemble\n",
        "ensemble_fS_rfc = VotingClassifier(estimators=[('rf', model1), ('gb', model2), ('lr', model3)])\n",
        "\n",
        "# Fit the ensemble model\n",
        "ensemble_fS_rfc.fit(X_train_featureSelected_rfc, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkB7FwBV-J3X"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = ensemble_fS_rfc.predict(X_val_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABktI5lK-KzX"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P18ihTuO-L5i"
      },
      "outputs": [],
      "source": [
        "# accuracy score for the logistic regression applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Ensemble: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LokLzXJ-NL_"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nhLxy-m-QrS"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFdfx1gQ-Sli"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('Confusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('Classification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7ZO10kM-dp7"
      },
      "outputs": [],
      "source": [
        "#PLOT DE ROC CURVE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYW5iPDn-ff8"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_ensemblemodel_fs_rfc = ensemble_fS_rfc.predict(testdf_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwMYJeV--gXF"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "ensemblemodel_submission_df_fs_rfc = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_ensemblemodel_fs_rfc\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjfvZWfk-n1c"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(ensemblemodel_submission_df_fs_rfc, 'ensemblemodel_submission_df_fs_rfc', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GokpkIEvmKsN"
      },
      "outputs": [],
      "source": [
        "#score de 0,77710"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKK6-10uX9VC"
      },
      "source": [
        "### Hyperparameterization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpWImPc9X9KL"
      },
      "outputs": [],
      "source": [
        "'''# Create the VotingClassifier\n",
        "ensemble_fS_lr = VotingClassifier(estimators=[\n",
        "    ('rf', model1),\n",
        "    ('gb', model2),\n",
        "    ('mlp', model3)\n",
        "])\n",
        "\n",
        "# Define the parameter grid\n",
        "param_dist = {\n",
        "    'rf__n_estimators': [200, 250, 300, 350, 400],\n",
        "    'rf__max_depth': [30, 40, 50, 60],\n",
        "    'rf__min_samples_split': [3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'gb__n_estimators': [100, 150, 200, 250],\n",
        "    'gb__max_depth': [3, 4, 5, 6],\n",
        "    'gb__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'gb__subsample': [0.7, 0.8, 0.9, 1.0],\n",
        "    'mlp__hidden_layer_sizes': [(50, 100, 50), (100,)],\n",
        "    'mlp__activation': ['tanh', 'relu'],\n",
        "    'mlp__solver': ['adam'],\n",
        "    'mlp__learning_rate': ['constant', 'adaptive'],\n",
        "    'mlp__alpha': [0.0001, 0.001, 0.01, 0.05]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=ensemble_fS_lr, param_distributions=param_dist, n_iter=50, cv=5, n_jobs=-1, verbose=2, scoring='f1_macro')\n",
        "random_search.fit(X_train_featureSelected_lr, y_train)\n",
        "print(\"Best parameters: \", random_search.best_params_)\n",
        "print(\"Best score: \", random_search.best_score_)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMsJ4ahpX_1C"
      },
      "source": [
        "### Model w/ Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTpV_KPrY1NO"
      },
      "outputs": [],
      "source": [
        "'''ensemble_model_fs_lr_hp = ensemble_fS_lr(subsample=0.8, n_estimators=100, min_samples_split=2, max_depth=4, learning_rate=0.1)\n",
        "ensemble_fs_lr_hp.fit(X_train_featureSelected_lr, y_train)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFEi7TFTZfoq"
      },
      "outputs": [],
      "source": [
        "'''# predictions to y_pred, using the method `predict()`.\n",
        "\n",
        "y_pred = ensemble_fs_lr_hp.predict(X_val_featureSelected_lr)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IlUD_DvZhCa"
      },
      "outputs": [],
      "source": [
        "'''# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10P618wyZjHx"
      },
      "outputs": [],
      "source": [
        "'''# accuracy score for the logistic regression applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Ensemble: \", accuracy)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWrL-b4HZlTJ"
      },
      "outputs": [],
      "source": [
        "'''y_pred_prob = ensemble_fs_lr_hp.predict_proba(X_val_featureSelected_lr)[:, 1]\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class = 'ovr')\n",
        "print(\"Ensemble ROC-AUC: \", roc_auc)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM1fEDFUZunj"
      },
      "outputs": [],
      "source": [
        "'''precision_score(y_val, y_pred, average = \"weighted\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgqdwghgZxTD"
      },
      "outputs": [],
      "source": [
        "'''recall_score(y_val, y_pred, average = \"weighted\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-tWnhClZ0E5"
      },
      "outputs": [],
      "source": [
        "'''# Get feature importance\n",
        "importances = ensemble_fs_lr_hp.feature_importances_\n",
        "\n",
        "# Print them out\n",
        "for feature, importance in zip(X_train_featureSelected_lr.columns, importances):\n",
        "    print(f\"The feature {feature} has an importance of {importance}\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnTTExacZ6zK"
      },
      "outputs": [],
      "source": [
        "'''print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn6iF-XIZ8Xs"
      },
      "outputs": [],
      "source": [
        "'''fpr, tpr, thresholds = roc_curve(y_val, y_pred_prob)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr, label='VotingClassifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Ensemble ROC Curve')\n",
        "plt.show()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoToTlqMZ96F"
      },
      "outputs": [],
      "source": [
        "'''# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_ensemble_fs_lr_hp = ensemble_fs_lr_hp.predict(testdf_featureSelected_lr)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-x_KX4SvaBXn"
      },
      "outputs": [],
      "source": [
        "'''# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "ensemblemodel_hp_submission_df_fs_lr = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_ensemble_fs_lr_hp\n",
        "})'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSQanoEHaTfu"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(ensemblemodel_hp_submission_df_fs_lr, '/content/drive/MyDrive/Data Mining II project/Results/hpp')'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnADfW_uqXje"
      },
      "source": [
        "## 4.4 Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8oyCScFqaNf"
      },
      "source": [
        "### FS with LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbnmjgN0qbhn"
      },
      "outputs": [],
      "source": [
        "# instance of LogisticRegression named as `log_model` with the default parameters and fit to your train data.\n",
        "\n",
        "lr_model_fs = LogisticRegression()\n",
        "lr_model_fs.fit(X_train_featureSelected_lr, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MCzYQNlqdTD"
      },
      "outputs": [],
      "source": [
        "# predictions to y_pred, using the method `predict()`.\n",
        "\n",
        "y_pred = lr_model_fs.predict(X_val_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiKup3-CqeQP"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPhLbPFTqgHe"
      },
      "outputs": [],
      "source": [
        "# accuracy score for the logistic regression applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Logistic Regression Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYVajxo9qhJT"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = lr_model_fs.predict_proba(X_val_featureSelected_lr)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"Logistic Regression ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixDmx7V5qhWc"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAYsVepCqjhX"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VFWf8X7ql8X"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaIc9ftEqnLf"
      },
      "outputs": [],
      "source": [
        "#plot de ROC CURVE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6_bRY9sqpQ8"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_lrmode_fs_lr = lr_model_fs.predict(testdf_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F5hepcRqq6r"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "lrmodel_submission_df_fs_lr = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_lrmode_fs_lr\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl8nGyWIqupZ"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(lrmodel_submission_df_fs_lr, 'lrmodel_submission_df_nV_fS_lr', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RBU5rDNNoNr"
      },
      "outputs": [],
      "source": [
        "#score: 0,63801"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHqKnqOrrJRG"
      },
      "source": [
        "### FS with RFC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKYYq_6ErTMO"
      },
      "outputs": [],
      "source": [
        "# instance of LogisticRegression named as `log_model` with the default parameters and fit to your train data.\n",
        "\n",
        "lr_model_fs = LogisticRegression()\n",
        "lr_model_fs.fit(X_train_featureSelected_rfc, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emi35Yy2rU8n"
      },
      "outputs": [],
      "source": [
        "# predictions to y_pred, using the method `predict()`.\n",
        "\n",
        "y_pred = lr_model_fs.predict(X_val_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPHm6u5UrUZz"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0L-sK2V1rW8o"
      },
      "outputs": [],
      "source": [
        "# accuracy score for the logistic regression applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Logistic Regression Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ9Vrq7krW6I"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = lr_model_fs.predict_proba(X_val_featureSelected_rfc)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"Logistic Regression ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FYmn-WOrWyC"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN-yZJorrYro"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTFt-bN7reNu"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FB2Co6IRrfC4"
      },
      "outputs": [],
      "source": [
        "# PLOT DE ROC CURVE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT_OeGA1rg_H"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_lrmode_fs_rfc = lr_model_fs.predict(testdf_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y2rIuWfrh2s"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "lrmodel_submission_df_fs_rfc = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_lrmode_fs_rfc\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIPwkZG8rnM1"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(lrmodel_submission_df_fs_rfc, 'lrmodel_submission_df_nV_fS_rfc', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly-Pw4RTNpzW"
      },
      "outputs": [],
      "source": [
        "#score: 0,63333"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d5axp3drpjV"
      },
      "source": [
        "## 4.5 Decision trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63_lYzHbvPCV"
      },
      "source": [
        "### FS with LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lENAoAJqrt7C"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "dt_model_lr = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model\n",
        "dt_model_lr.fit(X_train_featureSelected_lr, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxAQ1snavTXy"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Limit the tree depth for simplicity\n",
        "dt_model_lr = DecisionTreeClassifier(max_depth=3)\n",
        "dt_model_lr.fit(X_train_featureSelected_lr, y_train)\n",
        "\n",
        "# Unique classes and their corresponding class names\n",
        "class_names = ['Health-Conscious', 'Investor', 'Adventure Seeker', 'Fitness Enthusiast', 'Travel Enthusiast']\n",
        "\n",
        "# Plot the decision tree\n",
        "fig, ax = plt.subplots(figsize=(12, 12))  # Adjust size as needed\n",
        "plot_tree(dt_model_lr,\n",
        "          feature_names=X_train_featureSelected_lr.columns,\n",
        "          class_names=class_names,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkLu6PZ-vWI5"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = dt_model_lr.predict(X_val_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikbvc7i9vYSs"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Decision Tree Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPacQNabvZYZ"
      },
      "outputs": [],
      "source": [
        "# Calculate AUC-ROC\n",
        "y_pred_prob = dt_model_lr.predict_proba(X_val_featureSelected_lr)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"Decision Tree ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQFaQ5MYvakN"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIFHDaveva9Q"
      },
      "outputs": [],
      "source": [
        "#PLOT roc curve?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxZ4riJAvcl3"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set for the Kaggle competition\n",
        "test_predictions_dtmodel_fs_lr = dt_model_lr.predict(testdf_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK8oG_VWvdQU"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "dtmodel_submission_df_fs_lr = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_dtmodel_fs_lr\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sMVHlB7vkXU"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(dtmodel_submission_df_fs_lr, 'decisiontrees_submission_df_nV_fS_lr', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MiR6XLcNrty"
      },
      "outputs": [],
      "source": [
        "#score: 0,61279"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEfexXmvvlFY"
      },
      "source": [
        "### FS with RFC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07vCv-h0vmbA"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "dt_model_rfc = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model\n",
        "dt_model_rfc.fit(X_train_featureSelected_rfc, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYWSVWEevob8"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Limit the tree depth for simplicity\n",
        "dt_model_rfc = DecisionTreeClassifier(max_depth=3)\n",
        "dt_model_rfc.fit(X_train_featureSelected_rfc, y_train)\n",
        "\n",
        "# Unique classes and their corresponding class names\n",
        "class_names = ['Health-Conscious', 'Investor', 'Adventure Seeker', 'Fitness Enthusiast', 'Travel Enthusiast']\n",
        "\n",
        "# Plot the decision tree\n",
        "fig, ax = plt.subplots(figsize=(12, 12))  # Adjust size as needed\n",
        "plot_tree(dt_model_rfc,\n",
        "          feature_names=X_train_featureSelected_rfc.columns,\n",
        "          class_names=class_names,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO17EybVvnYh"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = dt_model_rfc.predict(X_val_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS1TXA77vqKW"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Decision Tree Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrYV4cDtvruC"
      },
      "outputs": [],
      "source": [
        "# Calculate AUC-ROC\n",
        "y_pred_prob = dt_model_rfc.predict_proba(X_val_featureSelected_rfc)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"Decision Tree ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o41s45Cavsgm"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRH3s4Wcvuat"
      },
      "outputs": [],
      "source": [
        "#plot roc curve?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC2fZbnKvwbs"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set for the Kaggle competition\n",
        "test_predictions_dtmodel_fs_rfc = dt_model_rfc.predict(testdf_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8AfEiULvx56"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "dtmodel_submission_df_fs_rfc = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_dtmodel_fs_rfc\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BdY7jufv3zx"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(dtmodel_submission_df_fs_rfc, 'decisiontrees_submission_df_nV_fS_rfc', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqj1p8XiNs-w"
      },
      "outputs": [],
      "source": [
        "#score: 0,61279"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xdt-fTqPV_N"
      },
      "source": [
        "## 4.6 Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB9xMFW8PZLr"
      },
      "source": [
        "### FS with LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJeX5LziPayI"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3GQaaymiCAe"
      },
      "outputs": [],
      "source": [
        "mlp_model_fs_lr = MLPClassifier()\n",
        "mlp_model_fs_lr.fit(X_train_featureSelected_lr, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeKXAJ_qiEFd"
      },
      "outputs": [],
      "source": [
        "# predictions to y_pred, using the method `predict()`.\n",
        "\n",
        "y_pred = mlp_model_fs_lr.predict(X_val_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJY-cHEhiFDz"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqwJn_gLiGEp"
      },
      "outputs": [],
      "source": [
        "# accuracy score for the Multi Layer Perceptron applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Multi-Layer Perceptron Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOVUo5qliGzE"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = mlp_model_fs_lr.predict_proba(X_val_featureSelected_lr)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"Multi layer Perceptron ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYr3HMqFiHy3"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a13bnsUNiI0_"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7R07sUFiL0b"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9MRo_naiNrw"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_mlpmodel_fs_lr = mlp_model_fs_lr.predict(testdf_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksBA3dh2iOfp"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "mlpmodel_submission_df_fs_lr = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_mlpmodel_fs_lr\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay9URQcbiURr"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(mlpmodel_submission_df_fs_lr, 'mlpmodel_submission_df_fs_lr', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4r_2rz2mCDS"
      },
      "outputs": [],
      "source": [
        "# score 0,7699"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj9ysaqniWur"
      },
      "source": [
        "### FS with RFC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO7XsPZpia25"
      },
      "outputs": [],
      "source": [
        "mlp_model_fs_rfc = MLPClassifier()\n",
        "mlp_model_fs_rfc.fit(X_train_featureSelected_rfc, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fkg_Z9J6ibu0"
      },
      "outputs": [],
      "source": [
        "# predictions to y_pred, using the method `predict()`.\n",
        "\n",
        "y_pred = mlp_model_fs_rfc.predict(X_val_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33hG2Gy6icrd"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lztDKhudicin"
      },
      "outputs": [],
      "source": [
        "# accuracy score for the Multi Layer Perceptron applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Multi-Layer Perceptron Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4fkCgRXicf8"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = mlp_model_fs_rfc.predict_proba(X_val_featureSelected_rfc)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"Multi layer Perceptron ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8zw-Cs6icdP"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1loqgloimMW"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXoGA-ERipyq"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k63rYpEisiz"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_mlpmodel_fs_rfc = mlp_model_fs_rfc.predict(testdf_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S0cNIpVitN6"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "mlpmodel_submission_df_fs_rfc = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_mlpmodel_fs_rfc\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hov15G2iz_Y"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(mlpmodel_submission_df_fs_rfc, 'mlpmodel_submission_df_fs_rfc', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF2VU92Ol7-g"
      },
      "outputs": [],
      "source": [
        "# score 0,757"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogu90XABqqED"
      },
      "source": [
        "## 4.7 Gradient Boosted Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbJgoTTVqxcr"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daNGYPA9q0Dh"
      },
      "source": [
        "### FS with LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-n2nLloq12O"
      },
      "outputs": [],
      "source": [
        "gbc_model_fs_lr = GradientBoostingClassifier()\n",
        "gbc_model_fs_lr.fit(X_train_featureSelected_lr, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UrWG8stq26o"
      },
      "outputs": [],
      "source": [
        "# predictions to y_pred, using the method `predict()`.\n",
        "\n",
        "y_pred = gbc_model_fs_lr.predict(X_val_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoIt8i5bq4La"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "602LUayKq49z"
      },
      "outputs": [],
      "source": [
        "# accuracy score for the logistic regression applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Gradient Boosting Classifier Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2Beu8L4q5-U"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = gbc_model_fs_lr.predict_proba(X_val_featureSelected_lr)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"Gradient Boosting Classifier ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWax_B8rq6zF"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2RV3dtDrB1b"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80cn3UtArESi"
      },
      "outputs": [],
      "source": [
        "# Get feature importance\n",
        "importances = gbc_model_fs_lr.feature_importances_\n",
        "\n",
        "# Print them out\n",
        "for feature, importance in zip(X_train_featureSelected_lr.columns, importances):\n",
        "    print(f\"The feature {feature} has an importance of {importance}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAwQUPSwrE_-"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCYjMBS-rGJZ"
      },
      "outputs": [],
      "source": [
        "#Plot de ROC CURVE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJnam_j_rHUB"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_gbcmodel_fs_lr = gbc_model_fs_lr.predict(testdf_featureSelected_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ6UHXmxrJBj"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "gbcmodel_submission_df_fs_lr = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_gbcmodel_fs_lr\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLIQsZMxrOA2"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(gbcmodel_submission_df_fs_lr, 'gbcmodel_submission_df_nV_fS_lr', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s87NIsauNxe2"
      },
      "outputs": [],
      "source": [
        "#score : 0,61279"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvgF_fegrSfv"
      },
      "source": [
        "### FS with RFC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixhoT-bOrUOC"
      },
      "outputs": [],
      "source": [
        "gbc_model_fs_rfc = GradientBoostingClassifier()\n",
        "gbc_model_fs_rfc.fit(X_train_featureSelected_rfc, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOmQsT1QrVj4"
      },
      "outputs": [],
      "source": [
        "# predictions to y_pred, using the method `predict()`.\n",
        "\n",
        "y_pred = gbc_model_fs_rfc.predict(X_val_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXdmXND9rWRN"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJxcvFx5rXHu"
      },
      "outputs": [],
      "source": [
        "# accuracy score for the logistic regression applied on insurance.\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Gradient Boosting Classifier Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krqsgrpjrYGx"
      },
      "outputs": [],
      "source": [
        "y_pred_prob = gbc_model_fs_rfc.predict_proba(X_val_featureSelected_rfc)\n",
        "roc_auc = roc_auc_score(y_val, y_pred_prob, multi_class='ovr')\n",
        "print(\"Gradient Boosting Classifier ROC-AUC: \", roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_ZoP22urfSQ"
      },
      "outputs": [],
      "source": [
        "precision_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoBQoi3drewR"
      },
      "outputs": [],
      "source": [
        "recall_score(y_val, y_pred, average = \"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YT1-Rnv4rgXH"
      },
      "outputs": [],
      "source": [
        "# Get feature importance\n",
        "importances = gbc_model_fs_rfc.feature_importances_\n",
        "\n",
        "# Print them out\n",
        "for feature, importance in zip(X_train_featureSelected_rfc.columns, importances):\n",
        "    print(f\"The feature {feature} has an importance of {importance}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al80h9YnrhP-"
      },
      "outputs": [],
      "source": [
        "print('Accuracy:', accuracy_score(y_val, y_pred))\n",
        "print('\\nConfusion Matrix:\\n', confusion_matrix(y_val, y_pred))\n",
        "print('\\nClassification Report:\\n', classification_report(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brL7Q1-oriNT"
      },
      "outputs": [],
      "source": [
        "#plot de roc curve?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ52iw1vrj46"
      },
      "outputs": [],
      "source": [
        "# FOR KAGGLE SUBMISSION\n",
        "\n",
        "test_predictions_gbcmodel_fs_rfc = gbc_model_fs_rfc.predict(testdf_featureSelected_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OCauFRJrlOX"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with the required columns (e.g., 'Id' and 'lifestyle_type')\n",
        "gbcmodel_submission_df_fs_rfc = pd.DataFrame({\n",
        "    \"citizen_id\": testdf.index,  # Replace \"Id\" with the actual ID column of your test dataset\n",
        "    \"lifestyle_type\": test_predictions_gbcmodel_fs_rfc\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtuxGYvnrmRC"
      },
      "outputs": [],
      "source": [
        "'''def save_versioned(df, base_filename, directory):\n",
        "    version = 1\n",
        "    filename = f\"{base_filename}_v{version}.csv\"\n",
        "    full_path = os.path.join(directory, filename)\n",
        "\n",
        "    while os.path.exists(full_path):\n",
        "        version += 1\n",
        "        filename = f\"{base_filename}_v{version}.csv\"\n",
        "        full_path = os.path.join(directory, filename)\n",
        "\n",
        "    df.to_csv(full_path, index=False)\n",
        "    print(f\"Saved to {full_path}\")\n",
        "\n",
        "# Usage example:\n",
        "save_versioned(gbcmodel_submission_df_fs_rfc, 'gbcmodel_submission_df_nV_fS_rfc', '/content/drive/MyDrive/Data Mining II project/Results')'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah7wPKbONzG2"
      },
      "outputs": [],
      "source": [
        "#score: 0,61279"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}